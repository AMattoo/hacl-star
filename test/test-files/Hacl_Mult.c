/* This file was auto-generated by KreMLin! */

#include "Hacl_Mult.h"


inline static bool Hacl_Impl_Lib_bn_is_bit_set(uint32_t len, uint64_t *input, uint32_t ind)
{
  uint32_t i = ind / (uint32_t)64U;
  uint32_t j = ind % (uint32_t)64U;
  uint64_t tmp = input[i];
  uint64_t tmp1 = tmp >> j & (uint64_t)1U;
  return tmp1 == (uint64_t)1U;
}

inline static void Hacl_Impl_Lib_bn_set_bit(uint32_t len, uint64_t *input, uint32_t ind)
{
  uint32_t i = ind / (uint32_t)64U;
  uint32_t j = ind % (uint32_t)64U;
  uint64_t tmp = input[i];
  input[i] = tmp | (uint64_t)1U << j;
}

inline static uint64_t Hacl_Impl_Lib_bval(uint32_t len, uint64_t *b, uint32_t i)
{
  if (i < len)
    return b[i];
  else
    return (uint64_t)0U;
}

inline static void Hacl_Impl_Lib_fill(uint32_t len, uint64_t *b, uint64_t z)
{
  KRML_CHECK_SIZE(sizeof(z), len);
  uint64_t buf[len];
  for (uint32_t _i = 0U; _i < len; ++_i)
    buf[_i] = z;
  for (uint32_t i = (uint32_t)0U; i < len; i = i + (uint32_t)1U)
  {
    uint64_t src_i = buf[i];
    b[i] = src_i;
  }
}

bool Hacl_Impl_Lib_eq_b(uint32_t len, uint8_t *b1, uint8_t *b2)
{
  KRML_CHECK_SIZE(sizeof(true), (uint32_t)1U);
  bool buf[1U];
  buf[0U] = true;
  for (uint32_t i = (uint32_t)0U; i < len; i = i + (uint32_t)1U)
  {
    bool a1 = buf[0U];
    uint8_t x0 = b1[i];
    uint8_t x1 = b2[i];
    bool a2 = x0 == x1;
    buf[0U] = a1 && a2;
  }
  bool r = buf[0U];
  return r;
}

inline void Hacl_Impl_Convert_text_to_nat(uint32_t len, uint8_t *input, uint64_t *res)
{
  uint32_t num_words = (len - (uint32_t)1U) / (uint32_t)8U + (uint32_t)1U;
  uint32_t tmpLen = (uint32_t)8U * num_words;
  uint32_t m = len % (uint32_t)8U;
  uint32_t ind;
  if (m == (uint32_t)0U)
    ind = (uint32_t)0U;
  else
    ind = (uint32_t)8U - m;
  KRML_CHECK_SIZE(sizeof (uint8_t), tmpLen);
  uint8_t buf[tmpLen];
  memset(buf, 0U, tmpLen * sizeof buf[0U]);
  uint8_t *tmp1 = buf + ind;
  for (uint32_t i = (uint32_t)0U; i < len; i = i + (uint32_t)1U)
  {
    uint8_t src_i = input[i];
    tmp1[i] = src_i;
  }
  for (uint32_t i = (uint32_t)0U; i < num_words; i = i + (uint32_t)1U)
    res[num_words - i - (uint32_t)1U] = load64_be(buf + (uint32_t)8U * i);
}

inline static bool
Hacl_Impl_Comparison_bn_is_less_(
  uint32_t aLen,
  uint64_t *a,
  uint32_t bLen,
  uint64_t *b,
  uint32_t i
)
{
  if (i > (uint32_t)0U)
  {
    uint32_t i1 = i - (uint32_t)1U;
    uint64_t t1 = a[i1];
    uint64_t t2 = Hacl_Impl_Lib_bval(bLen, b, i1);
    if (!(t1 == t2))
      if (t1 < t2)
        return true;
      else
        return false;
    else
      return Hacl_Impl_Comparison_bn_is_less_(aLen, a, bLen, b, i1);
  }
  else
    return false;
}

inline static bool
Hacl_Impl_Comparison_bn_is_less(uint32_t aLen, uint64_t *a, uint32_t bLen, uint64_t *b)
{
  return Hacl_Impl_Comparison_bn_is_less_(aLen, a, bLen, b, aLen);
}

typedef struct K___uint64_t_uint64_t_s
{
  uint64_t fst;
  uint64_t snd;
}
K___uint64_t_uint64_t;

inline static K___uint64_t_uint64_t
Hacl_Impl_Addition_addcarry_u64(uint64_t carry1, uint64_t a, uint64_t b)
{
  uint64_t t1 = a + carry1;
  uint64_t carry2;
  if (t1 < carry1)
    carry2 = (uint64_t)1U;
  else
    carry2 = (uint64_t)0U;
  uint64_t res = t1 + b;
  uint64_t carry3;
  if (res < t1)
    carry3 = carry2 + (uint64_t)1U;
  else
    carry3 = carry2;
  return ((K___uint64_t_uint64_t){ .fst = carry3, .snd = res });
}

inline static K___uint64_t_uint64_t
Hacl_Impl_Addition_subborrow_u64(uint64_t carry1, uint64_t a, uint64_t b)
{
  uint64_t res = a - b - carry1;
  uint64_t carry2;
  if (carry1 == (uint64_t)1U)
  {
    uint64_t ite;
    if (a <= b)
      ite = (uint64_t)1U;
    else
      ite = (uint64_t)0U;
    carry2 = ite;
  }
  else
  {
    uint64_t ite;
    if (a < b)
      ite = (uint64_t)1U;
    else
      ite = (uint64_t)0U;
    carry2 = ite;
  }
  return ((K___uint64_t_uint64_t){ .fst = carry2, .snd = res });
}

inline static uint64_t
Hacl_Impl_Addition_bn_sub(
  uint32_t aLen,
  uint64_t *a,
  uint32_t bLen,
  uint64_t *b,
  uint64_t *res
)
{
  uint64_t buf[1U] = { 0U };
  for (uint32_t i = (uint32_t)0U; i < aLen; i = i + (uint32_t)1U)
  {
    uint64_t t1 = a[i];
    uint64_t t2 = Hacl_Impl_Lib_bval(bLen, b, i);
    K___uint64_t_uint64_t scrut = Hacl_Impl_Addition_subborrow_u64(buf[0U], t1, t2);
    uint64_t c = scrut.fst;
    uint64_t res_i = scrut.snd;
    buf[0U] = c;
    res[i] = res_i;
  }
  uint64_t r = buf[0U];
  return r;
}

inline static uint64_t
Hacl_Impl_Addition_bn_add(
  uint32_t aLen,
  uint64_t *a,
  uint32_t bLen,
  uint64_t *b,
  uint64_t *res
)
{
  uint64_t buf[1U] = { 0U };
  for (uint32_t i = (uint32_t)0U; i < aLen; i = i + (uint32_t)1U)
  {
    uint64_t t1 = a[i];
    uint64_t t2 = Hacl_Impl_Lib_bval(bLen, b, i);
    K___uint64_t_uint64_t scrut = Hacl_Impl_Addition_addcarry_u64(buf[0U], t1, t2);
    uint64_t c = scrut.fst;
    uint64_t res_i = scrut.snd;
    buf[0U] = c;
    res[i] = res_i;
  }
  uint64_t r = buf[0U];
  return r;
}

inline static K___uint64_t_uint64_t
Hacl_Impl_Multiplication_bn_mul_by_limb_addj_f(
  uint64_t a_i,
  uint64_t l,
  uint64_t c,
  uint64_t r_ij
)
{
  FStar_UInt128_uint128
  res =
    FStar_UInt128_add(FStar_UInt128_add(FStar_UInt128_mul_wide(a_i, l),
        FStar_UInt128_uint64_to_uint128(c)),
      FStar_UInt128_uint64_to_uint128(r_ij));
  uint64_t r = FStar_UInt128_uint128_to_uint64(res);
  uint64_t c_ = FStar_UInt128_uint128_to_uint64(FStar_UInt128_shift_right(res, (uint32_t)64U));
  return ((K___uint64_t_uint64_t){ .fst = c_, .snd = r });
}

void
Hacl_Impl_Multiplication_bn_mul(
  uint32_t aLen,
  uint64_t *a,
  uint32_t bLen,
  uint64_t *b,
  uint64_t *res
)
{
  uint32_t resLen = aLen + bLen;
  Hacl_Impl_Lib_fill(resLen, res, (uint64_t)0U);
  uint64_t buf[1U] = { 0U };
  for (uint32_t i0 = (uint32_t)0U; i0 < bLen; i0 = i0 + (uint32_t)1U)
  {
    buf[0U] = (uint64_t)0U;
    uint64_t x2 = b[i0];
    for (uint32_t i = (uint32_t)0U; i < aLen; i = i + (uint32_t)1U)
    {
      uint32_t ij = i + i0;
      uint64_t res_ij = res[ij];
      K___uint64_t_uint64_t
      scrut = Hacl_Impl_Multiplication_bn_mul_by_limb_addj_f(a[i], x2, buf[0U], res_ij);
      uint64_t c = scrut.fst;
      uint64_t res_ij1 = scrut.snd;
      buf[0U] = c;
      res[ij] = res_ij1;
    }
    res[aLen + i0] = buf[0U];
  }
}

inline static Hacl_Impl_Multiplication_sign
Hacl_Impl_Multiplication_abs(uint32_t aLen, uint64_t *a, uint64_t *b, uint64_t *res)
{
  if (Hacl_Impl_Comparison_bn_is_less(aLen, a, aLen, b))
  {
    uint64_t uu____0 = Hacl_Impl_Addition_bn_sub(aLen, b, aLen, a, res);
    return Hacl_Impl_Multiplication_Negative;
  }
  else
  {
    uint64_t uu____1 = Hacl_Impl_Addition_bn_sub(aLen, a, aLen, b, res);
    return Hacl_Impl_Multiplication_Positive;
  }
}

bool
__eq__Hacl_Impl_Multiplication_sign(
  Hacl_Impl_Multiplication_sign y,
  Hacl_Impl_Multiplication_sign x
)
{
  switch (x)
  {
    case Hacl_Impl_Multiplication_Positive:
      {
        switch (y)
        {
          case Hacl_Impl_Multiplication_Positive:
            {
              return true;
            }
          default:
            {
              return false;
            }
        }
        break;
      }
    case Hacl_Impl_Multiplication_Negative:
      {
        switch (y)
        {
          case Hacl_Impl_Multiplication_Negative:
            {
              return true;
            }
          default:
            {
              return false;
            }
        }
        break;
      }
    default:
      {
        return false;
      }
  }
}

inline static void
Hacl_Impl_Multiplication_add_sign(
  uint32_t a0Len,
  uint64_t *c0,
  uint64_t *c1,
  uint64_t *c2,
  uint64_t *a0,
  uint64_t *a1,
  uint64_t *a2,
  uint64_t *b0,
  uint64_t *b1,
  uint64_t *b2,
  Hacl_Impl_Multiplication_sign sa2,
  Hacl_Impl_Multiplication_sign sb2,
  uint32_t resLen,
  uint64_t *res
)
{
  uint32_t c0Len = a0Len + a0Len;
  uint64_t *res1 = res;
  uint64_t c = Hacl_Impl_Addition_bn_add(c0Len, c0, c0Len, c1, res1);
  res[c0Len] = c;
  if
  (
    __eq__Hacl_Impl_Multiplication_sign(sa2,
      Hacl_Impl_Multiplication_Positive)
    && __eq__Hacl_Impl_Multiplication_sign(sb2, Hacl_Impl_Multiplication_Positive)
    ||
      __eq__Hacl_Impl_Multiplication_sign(sa2,
        Hacl_Impl_Multiplication_Negative)
      && __eq__Hacl_Impl_Multiplication_sign(sb2, Hacl_Impl_Multiplication_Negative)
  )
  {
    uint64_t uu____0 = Hacl_Impl_Addition_bn_sub(resLen, res, c0Len, c2, res);
  }
  else
  {
    uint64_t uu____1 = Hacl_Impl_Addition_bn_add(resLen, res, c0Len, c2, res);
  }
}

void
Hacl_Impl_Multiplication_karatsuba_(
  uint32_t k,
  uint32_t pow2_i,
  uint32_t aLen,
  uint64_t *a,
  uint64_t *b,
  uint64_t *tmp,
  uint64_t *res
)
{
  uint32_t pow2_i0 = pow2_i / (uint32_t)2U;
  if (aLen < k)
    Hacl_Impl_Multiplication_bn_mul(aLen, a, aLen, b, res);
  else
  {
    uint64_t *a0 = a;
    uint64_t *b0 = b;
    uint64_t *tmp0 = tmp;
    uint64_t *c0 = res;
    Hacl_Impl_Multiplication_karatsuba_(k, pow2_i0, pow2_i0, a0, b0, tmp0, c0);
    uint64_t *a1 = a + pow2_i0;
    uint64_t *b1 = b + pow2_i0;
    uint64_t *tmp01 = tmp;
    uint64_t *c1 = res + pow2_i;
    Hacl_Impl_Multiplication_karatsuba_(k, pow2_i0, pow2_i0, a1, b1, tmp01, c1);
    uint64_t *a2 = tmp;
    uint64_t *b2 = tmp + pow2_i0;
    Hacl_Impl_Multiplication_sign sa2 = Hacl_Impl_Multiplication_abs(pow2_i0, a0, a1, a2);
    Hacl_Impl_Multiplication_sign sb2 = Hacl_Impl_Multiplication_abs(pow2_i0, b0, b1, b2);
    uint64_t *c2 = tmp + pow2_i;
    uint64_t *tmp02 = tmp + (uint32_t)4U * pow2_i0;
    Hacl_Impl_Multiplication_karatsuba_(k, pow2_i0, pow2_i0, a2, b2, tmp02, c2);
    uint32_t tmp1Len = pow2_i + (uint32_t)1U;
    uint64_t *tmp1 = tmp + (uint32_t)4U * pow2_i0;
    Hacl_Impl_Multiplication_add_sign(pow2_i0,
      c0,
      c1,
      c2,
      a0,
      a1,
      a2,
      b0,
      b1,
      b2,
      sa2,
      sb2,
      tmp1Len,
      tmp1);
    uint32_t res1Len = pow2_i0 + pow2_i;
    uint64_t *res1 = res + pow2_i0;
    uint64_t uu____0 = Hacl_Impl_Addition_bn_add(res1Len, res1, tmp1Len, tmp1, res1);
  }
}
