include "../../../../arch/x64/X64.Vale.InsBasic.vaf"
include "../../../../arch/x64/X64.Vale.InsMem.vaf"
include{:fstar}{:open} "FastMul_helpers"
//include{:fstar}{:open} "Prop_s"
module X64.FastMul

#reset-options "--z3rlimit 30"

#verbatim{:interface}{:implementation}
open Types_s
open Arch.Types
open X64.Machine_s
open X64.Memory
open X64.Vale.State
open X64.Vale.Decls
open X64.Vale.InsBasic
open X64.Vale.InsMem
open X64.Vale.QuickCode
open X64.Vale.QuickCodes
open FastMul_helpers
open FStar.Tactics

//open FStar.Tactics
//open CanonCommSemiring
#endverbatim

type tactic:Type(0) extern;
const int_canon:tactic extern;
ghost procedure assert_by_tactic(ghost p:prop, ghost t:tactic) extern;


#reset-options "--z3rlimit 20"
procedure{:quick} fast_multiply_a0b(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;
        inB_ptr @= rcx;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        b0 := buffer64_read(inB_b, 0, mem);
        b1 := buffer64_read(inB_b, 1, mem);
        b2 := buffer64_read(inB_b, 2, mem);
        b3 := buffer64_read(inB_b, 3, mem);

        a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;
    reads
        dst_ptr; inA_ptr; inB_ptr; memTaint;

    modifies
        rax; rdx; r8; r9; r10; r11; r12; r13; r14;
        mem; efl;

    requires
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);
        validSrcAddrs64(mem, inB_ptr, inB_b, 4, memTaint, Secret);

    ensures
        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let a0b := d0 + pow2_64 * d1 + pow2_128 * r12 + pow2_192 * r14 + pow2_256 * rax; 
        a0b == a0 * b;

        rax < pow2_64 - 1;

        validSrcAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        modifies_buffer(dst_b, old(mem), mem);
{
    xor_lemmas();

//    "movq   (%1), %%rdx; " /* A[0] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[0]*B[0] */    "xorl %%r10d, %%r10d ;"                           "movq  %%r8,  (dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[0]*B[1] */    "adox  %%r9, %%r10 ;"                             "movq %%r10, 8(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[0]*B[2] */    "adox %%r11, %%r12 ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[0]*B[3] */    "adox %%r13, %%r14 ;"                                                       "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"

    Load64_buffer(rdx, inA_ptr,  0, Secret, inA_b, 0);     /* A[0] */
    // TODO: It would be really nice to not need the call to lemma_load_mem64, but it's the only connection between eval_operand and buffer64_read
    lemma_load_mem64(inB_b, 0, mem);
    /* The Xo64 clears the flags used for carry bits; NOTE: Original code uses xorl with r10d, maybe produces smaller code? */
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0, Secret));  /* A[0]*B[0] */ Xor64(r10, r10);     lemma_prod_bounds(r9, r8, a0, b0);      Store64_buffer(dst_ptr,  r8, 0, Secret, dst_b, 0);

    lemma_load_mem64(inB_b, 1, mem);
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1, Secret));  /* A[0]*B[1] */ ghost var a0b1_lo := r10; lemma_prod_bounds(r11, r10, a0, b1);  Adox64Wrap(r10,  r9);    Store64_buffer(dst_ptr, r10, 8, Secret, dst_b, 1);

    ghost var d0 := buffer64_read(dst_b, 0, mem);
    ghost var d1 := buffer64_read(dst_b, 1, mem);
    ghost var overflow0 := overflow(efl);
    ghost var carry := if overflow(efl) then 1 else 0;          
    ghost var a0b0b1 := d0 + pow2_64 * d1 + pow2_128 * (r11 + carry);
//    simple_helper(a0, b0, b1, d0, r9, a0b1_lo, r11, r10, overflow(efl));
//    assert a0b0b1 == a0 * (b0 + pow2_64 * b1);   // PASSES in both modes using lemma above

// These work:
//    assert_by_tactic(a0 * (b0 + pow2_64 * b1) == a0 * b0 + pow2_64 * (a0 * b1), int_canon);
//    assert a0b0b1 == a0 * (b0 + pow2_64 * b1);

    //assert_by_tactic(a0b0b1 == a0 * (b0 + pow2_64 * b1), int_canon);   // FAILS 
    lemma_load_mem64(inB_b, 2, mem);
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2, Secret));  /* A[0]*B[2] */ ghost var a0b2_lo := r12; lemma_prod_bounds(r13, r12, a0, b2);  Adox64Wrap(r12, r11);
    ghost var overflow1 := overflow(efl);
    lemma_load_mem64(inB_b, 3, mem);
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3, Secret));  /* A[0]*B[3] */ ghost var a0b3_lo := r14; lemma_prod_bounds(rdx, r14, a0, b3);  Adox64Wrap(r14, r13);    Mov64(rax, 0);
    ghost var overflow2 := overflow(efl);
    /*******************************************/                  Adox64Wrap(rax, rdx);

    carry := if overflow2 then 1 else 0;      
    ghost var carry_new := if overflow(efl) then 1 else 0;
    //ghost var a0b := d0 + pow2_64 * d1 + pow2_128 * r12 + pow2_192 * r14 + pow2_256 * (rdx + carry);
    ghost var a0b := d0 + pow2_64 * d1 + pow2_128 * r12 + pow2_192 * r14 + pow2_256 * rax + pow2_320 * carry_new;

//    a0b_helper(a0, b0, b1, b2, b3, 
//               d0,      r9,
//               a0b1_lo, r11,
//               a0b2_lo, r13,
//               a0b3_lo, rdx,
//               d1, r12, r14,
//               overflow0, overflow1, overflow2);
//    assert a0 * b == a0b;   // PASSES 

    assert_by_tactic(a0 * b == a0*b0 + pow2_64 * (a0*b1) + pow2_128 * (a0*b2) + pow2_192 * (a0*b3), int_canon);   // PASSES 
    assert a0b == a0 * b;   // PASSES (with the assert_by_tactic above)
    //assert_by_tactic(a0b == a0 * b, int_canon);   // FAILS
    
    assert carry_new == 0;
    assert rax < pow2_64 - 1;
}


#reset-options "--z3rlimit 300"
procedure{:quick} fast_multiply_a1b(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;
        inB_ptr @= rcx;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        b0 := buffer64_read(inB_b, 0, mem);
        b1 := buffer64_read(inB_b, 1, mem);
        b2 := buffer64_read(inB_b, 2, mem);
        b3 := buffer64_read(inB_b, 3, mem);

        a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;
    reads
        dst_ptr; inA_ptr; inB_ptr; memTaint;

    modifies
        rax; rdx; r8; r9; r10; r11; r12; r13; r14;
        mem; efl;

    requires
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);
        validSrcAddrs64(mem, inB_ptr, inB_b, 4, memTaint, Secret);
        
        rax < pow2_64 - 1;

        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let a0b := d0 + pow2_64 * d1 + pow2_128 * r12 + pow2_192 * r14 + pow2_256 * rax; 
        a0b == a0 * b;

    ensures
        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        pow2_two(a0, a1) * b == pow2_six(d0, d1, d2, r12, r14, rax);

        validSrcAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        modifies_buffer(dst_b, old(mem), mem);
{
    xor_lemmas();

    ghost var a0b_0 := buffer64_read(dst_b, 0, mem);
    ghost var a0b_1 := buffer64_read(dst_b, 1, mem);
    ghost var a0b_2 := r12;
    ghost var a0b_3 := r14;
    ghost var a0b_4 := rax;
    ghost var a0b := pow2_five(a0b_0, a0b_1, a0b_2, a0b_3, a0b_4);
//
//    "movq  8(A), %%rdx; " /* A[1] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[1]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 8(dst),  %%r8 ;"    "movq  %%r8,  8(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[1]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 16(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[1]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"                              "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[1]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"                              "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"

    Load64_buffer(rdx, inA_ptr,  8, Secret, inA_b, 1);     /* A[1] */

    lemma_load_mem64(inB_b, 0, mem);    
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0, Secret));  /* A[1]*B[0] */ lemma_prod_bounds(r9, r8, a1, b0); 
    lemma_load_mem64(dst_b, 1, mem);    
    Xor64(r10, r10);  ghost var a1b_0 := r8;      
    Adcx64Wrap(r8, Mem(dst_ptr,  8, dst_b, 1, Secret));   
    Store64_buffer(dst_ptr, r8,  8, Secret, dst_b, 1);  // REVIEW: Why not combine the Adcx with the Store?

    lemma_load_mem64(inB_b, 1, mem);    
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1, Secret));  /* A[1]*B[1] */ lemma_prod_bounds(r11, r10, a1, b1);  lemma_overflow(r11, r10, r9, bool_bit(overflow(efl)));
    Adox64Wrap(r10,  r9);  ghost var a1b_1 := r10;      // At this point, overflow = 0, r9 < 2^64 - 1, and (r10 is <= 1 (so no new overflow), or r11 < 2^64-2)
    Adcx64Wrap(r10, r12);                         
    Store64_buffer(dst_ptr, r10, 16, Secret, dst_b, 2); 

    lemma_load_mem64(inB_b, 2, mem);    
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2, Secret));  /* A[1]*B[2] */ lemma_prod_bounds(r13, r12, a1, b2);  lemma_overflow(r13, r12, r11, bool_bit(overflow(efl)));
    Adox64Wrap(r12, r11);  ghost var a1b_2 := r12;      // At this point, either r13 < 2^64-2 or (r12 <= 1, and (overflow = 0 or r11 < 2^64 - 2)).  RHS of the first or means no overflow
    Adcx64Wrap(r12, r14); 
    Mov64( r8, 0); 

    lemma_load_mem64(inB_b, 3, mem);    
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3, Secret));  /* A[1]*B[3] */ lemma_prod_bounds(rdx, r14, a1, b3);  lemma_overflow(rdx, r14, r13, bool_bit(overflow(efl)));
    ghost var old_carry    := bool_bit(cf(efl));
    ghost var old_overflow := bool_bit(overflow(efl));
    Adox64Wrap(r14, r13);  ghost var a1b_3 := r14;      // If rdx = 2^64 - 1, then we know r14 <= 1.  If r13 < 2^64-2, then no new overflow.  Else there wasn't any previous overflow, so r13 can absorb the 1 from r14 without overflowing.
    Adcx64Wrap(r14, rax);                         
    Mov64(rax, 0);
    /*******************************************/  Adox64Wrap(rax, rdx);  ghost var a1b_4 := rax;  ghost var overflow_bit := bool_bit(overflow(efl));  Adcx64Wrap(rax, r8); 

    assert overflow_bit == 0;

    ghost var carry_bit := bool_bit(cf(efl));
    assert carry_bit == 0;

    ghost var d0 := buffer64_read(dst_b, 0, mem);
    ghost var d1 := buffer64_read(dst_b, 1, mem);
    ghost var d2 := buffer64_read(dst_b, 2, mem);

    ghost var a1b := pow2_five(a1b_0, a1b_1, a1b_2, a1b_3, a1b_4);
    ghost var a0a1b := pow2_seven(d0, d1, d2, r12, r14, rax, carry_bit);

    assert_by_tactic(a1 * b == pow2_four(a1*b0, a1*b1, a1*b2, a1*b3), int_canon);   // PASSES
    assert a1b == a1 * b;  // PASSES

    lemma_sum_a1b(
              a0, a1,
              a0b, a0b_0, a0b_1, a0b_2, a0b_3, a0b_4,
              a1b, a1b_0, a1b_1, a1b_2, a1b_3, a1b_4,
              b, b0, b1, b2, b3,
              d1, d2, r12, r14, rax,
              carry_bit); 
    assert pow2_two(a0, a1) * b == a0a1b;   // Conclusion from the lemma
}

#reset-options "--z3rlimit 300"
procedure{:quick} fast_multiply_a2b(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;
        inB_ptr @= rcx;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        b0 := buffer64_read(inB_b, 0, mem);
        b1 := buffer64_read(inB_b, 1, mem);
        b2 := buffer64_read(inB_b, 2, mem);
        b3 := buffer64_read(inB_b, 3, mem);

        a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;
    reads
        dst_ptr; inA_ptr; inB_ptr; memTaint;

    modifies
        rax; rdx; r8; r9; r10; r11; r12; r13; r14;
        mem; efl;

    requires
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);
        validSrcAddrs64(mem, inB_ptr, inB_b, 4, memTaint, Secret);

        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        mul_nats(pow2_two(a0, a1), b) == pow2_six(d0, d1, d2, r12, r14, rax);
    ensures
        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        let d3 := buffer64_read(dst_b, 3, mem);
        pow2_three(a0, a1, a2) * b == pow2_seven(d0, d1, d2, d3, r12, r14, rax);

        validSrcAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        modifies_buffer(dst_b, old(mem), mem);
{
    xor_lemmas();

    ghost var a0a1b_0 := buffer64_read(dst_b, 0, mem);
    ghost var a0a1b_1 := buffer64_read(dst_b, 1, mem);
    ghost var a0a1b_2 := buffer64_read(dst_b, 2, mem);
    ghost var a0a1b_3 := r12;
    ghost var a0a1b_4 := r14;
    ghost var a0a1b_5 := rax;
    ghost var a0a1b := pow2_six(a0a1b_0, a0a1b_1, a0a1b_2, a0a1b_3, a0a1b_4, a0a1b_5);

//
//    "movq 16(A), %%rdx; " /* A[2] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[2]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 16(dst), %%r8 ;"    "movq  %%r8, 16(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[2]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 24(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[2]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"                              "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[2]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"                              "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"

    Load64_buffer(rdx, inA_ptr,  16, Secret, inA_b, 2);     /* A[2] */

    lemma_load_mem64(inB_b, 0, mem);    
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0, Secret));  /* A[2]*B[0] */ lemma_prod_bounds(r9, r8, a2, b0); 
    lemma_load_mem64(dst_b, 2, mem);    
    Xor64(r10, r10);  ghost var a2b_0 := r8;      
    Adcx64Wrap(r8, Mem(dst_ptr,  16, dst_b, 2, Secret));   
    Store64_buffer(dst_ptr, r8,  16, Secret, dst_b, 2);  // REVIEW: Why not combine the Adcx with the Store?

    lemma_load_mem64(inB_b, 1, mem);    
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1, Secret));  /* A[2]*B[1] */ lemma_prod_bounds(r11, r10, a2, b1);  lemma_overflow(r11, r10, r9, bool_bit(overflow(efl)));
    Adox64Wrap(r10,  r9);  ghost var a2b_1 := r10;  
    Adcx64Wrap(r10, r12);                         
    Store64_buffer(dst_ptr, r10, 24, Secret, dst_b, 3); 

    lemma_load_mem64(inB_b, 2, mem);    
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2, Secret));  /* A[2]*B[2] */ lemma_prod_bounds(r13, r12, a2, b2);  lemma_overflow(r13, r12, r11, bool_bit(overflow(efl)));
    Adox64Wrap(r12, r11);  ghost var a2b_2 := r12; 
    Adcx64Wrap(r12, r14); 
    Mov64( r8, 0); 

    lemma_load_mem64(inB_b, 3, mem);    
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3, Secret));  /* A[2]*B[3] */ lemma_prod_bounds(rdx, r14, a2, b3);  lemma_overflow(rdx, r14, r13, bool_bit(overflow(efl))); 
    ghost var old_carry    := bool_bit(cf(efl));
    ghost var old_overflow := bool_bit(overflow(efl));
    Adox64Wrap(r14, r13);  ghost var a2b_3 := r14; 
    Adcx64Wrap(r14, rax);                         
    Mov64(rax, 0);
    /*******************************************/  Adox64Wrap(rax, rdx);  ghost var a2b_4 := rax;    Adcx64Wrap(rax, r8); 

    ghost var carry_bit    := bool_bit(cf(efl)); 
    ghost var overflow_bit := bool_bit(overflow(efl));

    assert overflow_bit == 0;
    assert carry_bit == 0;

    ghost var d0 := buffer64_read(dst_b, 0, mem);
    ghost var d1 := buffer64_read(dst_b, 1, mem);
    ghost var d2 := buffer64_read(dst_b, 2, mem);
    ghost var d3 := buffer64_read(dst_b, 3, mem);

    ghost var a2b := pow2_five(a2b_0, a2b_1, a2b_2, a2b_3, a2b_4);
    ghost var a0a1a2b := pow2_seven(d0, d1, d2, d3, r12, r14, rax);

    assert_by_tactic(a2 * b == pow2_four(a2*b0, a2*b1, a2*b2, a2*b3), int_canon);   // PASSES
    assert a2b == a2 * b;  // PASSES

    lemma_sum_a2b(a0, a1, a2,
              a0a1b, a0a1b_0, a0a1b_1, a0a1b_2, a0a1b_3, a0a1b_4, a0a1b_5,
              a2b, a2b_0, a2b_1, a2b_2, a2b_3, a2b_4,
              b, b0, b1, b2, b3,
              d2, d3, r12, r14, rax); 
    assert pow2_three(a0, a1, a2) * b == a0a1a2b;   // Conclusion from the lemma.  // PASSES
    assert d0 == a0a1b_0;       // PASSES
    assert d1 == a0a1b_1;       // PASSES
    assert pow2_three(a0, a1, a2) * b == pow2_seven(d0, d1, d2, d3, r12, r14, rax);
}



#reset-options "--z3rlimit 300"
procedure{:quick} {:verify true} fast_multiply_a3b(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;
        inB_ptr @= rcx;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        b0 := buffer64_read(inB_b, 0, mem);
        b1 := buffer64_read(inB_b, 1, mem);
        b2 := buffer64_read(inB_b, 2, mem);
        b3 := buffer64_read(inB_b, 3, mem);

        a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;
    reads
        dst_ptr; inA_ptr; inB_ptr; memTaint;

    modifies
        rax; rdx; r8; r9; r10; r11; r12; r13; r14;
        mem; efl;

    requires
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);
        validSrcAddrs64(mem, inB_ptr, inB_b, 4, memTaint, Secret);

        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        let d3 := buffer64_read(dst_b, 3, mem);
        pow2_three(a0, a1, a2) * b == pow2_seven(d0, d1, d2, d3, r12, r14, rax);
    ensures
        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        let d3 := buffer64_read(dst_b, 3, mem);
        let d4 := buffer64_read(dst_b, 4, mem);
        let d5 := buffer64_read(dst_b, 5, mem);
        let d6 := buffer64_read(dst_b, 6, mem);
        let d7 := buffer64_read(dst_b, 7, mem);
        pow2_four(a0, a1, a2, a3) * b == pow2_eight(d0, d1, d2, d3, d4, d5, d6, d7);

        validSrcAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        modifies_buffer(dst_b, old(mem), mem);
{
    xor_lemmas();

    ghost var a0a1a2b_0 := buffer64_read(dst_b, 0, mem);
    ghost var a0a1a2b_1 := buffer64_read(dst_b, 1, mem);
    ghost var a0a1a2b_2 := buffer64_read(dst_b, 2, mem);
    ghost var a0a1a2b_3 := buffer64_read(dst_b, 3, mem);
    ghost var a0a1a2b_4 := r12;
    ghost var a0a1a2b_5 := r14;
    ghost var a0a1a2b_6 := rax;
    ghost var a0a1a2b := pow2_seven(a0a1a2b_0, a0a1a2b_1, a0a1a2b_2, a0a1a2b_3, a0a1a2b_4, a0a1a2b_5, a0a1a2b_6);

//
//    "movq 24(A), %%rdx; " /* A[3] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[3]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 24(dst), %%r8 ;"   "movq  %%r8, 24(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[3]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 32(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[3]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"    "movq %%r12, 40(dst) ;"    "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[3]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"    "movq %%r14, 48(dst) ;"    "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"    "movq %%rax, 56(dst) ;"

    Load64_buffer(rdx, inA_ptr,  24, Secret, inA_b, 3);     /* A[3] */

    lemma_load_mem64(inB_b, 0, mem);    
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0, Secret));  /* A[3]*B[0] */ lemma_prod_bounds(r9, r8, a3, b0); 
    lemma_load_mem64(dst_b, 3, mem);    
    Xor64(r10, r10);  ghost var a3b_0 := r8;      
    Adcx64Wrap(r8, Mem(dst_ptr,  24, dst_b, 3, Secret));   
    Store64_buffer(dst_ptr, r8,  24, Secret, dst_b, 3);  // REVIEW: Why not combine the Adcx with the Store?

    lemma_load_mem64(inB_b, 1, mem);    
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1, Secret));  /* A[3]*B[1] */ lemma_prod_bounds(r11, r10, a3, b1);  lemma_overflow(r11, r10, r9, bool_bit(overflow(efl)));
    Adox64Wrap(r10,  r9);  ghost var a3b_1 := r10;  
    Adcx64Wrap(r10, r12);                         
    Store64_buffer(dst_ptr, r10, 32, Secret, dst_b, 4); 

    lemma_load_mem64(inB_b, 2, mem);    
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2, Secret));  /* A[3]*B[2] */ lemma_prod_bounds(r13, r12, a3, b2);  lemma_overflow(r13, r12, r11, bool_bit(overflow(efl)));
    Adox64Wrap(r12, r11);  ghost var a3b_2 := r12; 
    Adcx64Wrap(r12, r14); 
    Store64_buffer(dst_ptr, r12, 40, Secret, dst_b, 5); 
    Mov64( r8, 0); 

    lemma_load_mem64(inB_b, 3, mem);    
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3, Secret));  /* A[3]*B[3] */ lemma_prod_bounds(rdx, r14, a3, b3);  lemma_overflow(rdx, r14, r13, bool_bit(overflow(efl))); 
    ghost var old_carry    := bool_bit(cf(efl));
    ghost var old_overflow := bool_bit(overflow(efl));
    Adox64Wrap(r14, r13);  ghost var a3b_3 := r14; 
    Adcx64Wrap(r14, rax);                         
    Store64_buffer(dst_ptr, r14, 48, Secret, dst_b, 6); 
    Mov64(rax, 0);
    /*******************************************/  Adox64Wrap(rax, rdx);  ghost var a3b_4 := rax;    Adcx64Wrap(rax, r8); 
    Store64_buffer(dst_ptr, rax, 56, Secret, dst_b, 7); 

    ghost var carry_bit    := bool_bit(cf(efl)); 
    ghost var overflow_bit := bool_bit(overflow(efl));

    assert overflow_bit == 0;
    assert carry_bit == 0;

    ghost var d0 := buffer64_read(dst_b, 0, mem);
    ghost var d1 := buffer64_read(dst_b, 1, mem);
    ghost var d2 := buffer64_read(dst_b, 2, mem);
    ghost var d3 := buffer64_read(dst_b, 3, mem);
    ghost var d4 := buffer64_read(dst_b, 4, mem);
    ghost var d5 := buffer64_read(dst_b, 5, mem);
    ghost var d6 := buffer64_read(dst_b, 6, mem);
    ghost var d7 := buffer64_read(dst_b, 7, mem);

    ghost var a3b := pow2_five(a3b_0, a3b_1, a3b_2, a3b_3, a3b_4);
    ghost var a0a1a2a3b := pow2_eight(d0, d1, d2, d3, d4, d5, d6, d7);

    assert_by_tactic(a3 * b == pow2_four(a3*b0, a3*b1, a3*b2, a3*b3), int_canon);   // PASSES
    assert a3b == a3 * b;  // PASSES

    lemma_sum_a3b(a0, a1, a2, a3,
              a0a1a2b, a0a1a2b_0, a0a1a2b_1, a0a1a2b_2, a0a1a2b_3, a0a1a2b_4, a0a1a2b_5, a0a1a2b_6,
              a3b, a3b_0, a3b_1, a3b_2, a3b_3, a3b_4,
              b, b0, b1, b2, b3,
              d3, d4, d5, d6, d7); 
//    assert pow2_four(a0, a1, a2, a3) * b == a0a1a2a3b;   // Conclusion from the lemma.  // PASSES
}


/*
#reset-options "--z3rlimit 20"

procedure{:quick} fast_multiply(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;
        inB_ptr @= rcx;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        b0 := buffer64_read(inB_b, 0, mem);
        b1 := buffer64_read(inB_b, 1, mem);
        b2 := buffer64_read(inB_b, 2, mem);
        b3 := buffer64_read(inB_b, 3, mem);

        a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;
    reads
        dst_ptr; inA_ptr; inB_ptr; memTaint;

    modifies
        rax; rdx; r8; r9; r10; r11; r12; r13; r14;
        mem; efl;

    requires
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);
        validSrcAddrs64(mem, inB_ptr, inB_b, 4, memTaint, Secret);

    ensures
//        let d0 := buffer64_read(dst_b, 0, mem);
//        let d1 := buffer64_read(dst_b, 1, mem);
//        let d2 := buffer64_read(dst_b, 2, mem);
//        let d3 := buffer64_read(dst_b, 3, mem);
//        let d4 := buffer64_read(dst_b, 4, mem);
//        let d5 := buffer64_read(dst_b, 5, mem);
//        let d6 := buffer64_read(dst_b, 6, mem);
//        let d7 := buffer64_read(dst_b, 7, mem);
//
//        let d := d0 + pow2_64 * d1 + pow2_128 * d2 + pow2_192 * d3 +
//                 pow2_256 * d4 + pow2_320 * d5 + pow2_384 * d6 + pow2_448 * d7;
////        d == a * b;
//        validSrcAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
//        modifies_buffer(dst_b, old(mem), mem);
{
    xor_lemmas();

//    "movq   (%1), %%rdx; " /* A[0] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[0]*B[0] */    "xorl %%r10d, %%r10d ;"                           "movq  %%r8,  (dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[0]*B[1] */    "adox  %%r9, %%r10 ;"                             "movq %%r10, 8(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[0]*B[2] */    "adox %%r11, %%r12 ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[0]*B[3] */    "adox %%r13, %%r14 ;"                                                       "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"

    Load64_buffer(rdx, inA_ptr,  0, Secret, inA_b, 0);     /* A[0] */
    // TODO: It would be really nice to not need the call to lemma_load_mem64, but it's the only connection between eval_operand and buffer64_read
    lemma_load_mem64(inB_b, 0, mem);
    /* The Xo64 clears the flags used for carry bits; NOTE: Original code uses xorl with r10d, maybe produces smaller code? */
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0, Secret));  /* A[0]*B[0] */ Xor64(r10, r10);         Store64_buffer(dst_ptr,  r8, 0, Secret, dst_b, 0);

    lemma_load_mem64(inB_b, 1, mem);
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1, Secret));  /* A[0]*B[1] */ ghost var a0b1_lo := r10; Adox64Wrap(r10,  r9);    Store64_buffer(dst_ptr, r10, 8, Secret, dst_b, 1);

    ghost var d0 := buffer64_read(dst_b, 0, mem);
    ghost var d1 := buffer64_read(dst_b, 1, mem);
    ghost var overflow0 := overflow(efl);
    ghost var carry := if overflow(efl) then 1 else 0;          
    ghost var a0b0b1 := d0 + pow2_64 * d1 + pow2_128 * (r11 + carry);
//    simple_helper(a0, b0, b1, d0, r9, a0b1_lo, r11, r10, overflow(efl));
//    assert a0b0b1 == a0 * (b0 + pow2_64 * b1);   // PASSES in both modes using lemma above

// These work:
//    assert_by_tactic(a0 * (b0 + pow2_64 * b1) == a0 * b0 + pow2_64 * (a0 * b1), int_canon);
//    assert a0b0b1 == a0 * (b0 + pow2_64 * b1);

    //assert_by_tactic(a0b0b1 == a0 * (b0 + pow2_64 * b1), int_canon);   // FAILS 
    lemma_load_mem64(inB_b, 2, mem);
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2, Secret));  /* A[0]*B[2] */ ghost var a0b2_lo := r12; Adox64Wrap(r12, r11);
    ghost var overflow1 := overflow(efl);
    lemma_load_mem64(inB_b, 3, mem);
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3, Secret));  /* A[0]*B[3] */ ghost var a0b3_lo := r14; Adox64Wrap(r14, r13);    Mov64(rax, 0);
    ghost var overflow2 := overflow(efl);
    /*******************************************/                  Adox64Wrap(rax, rdx);

    carry := if overflow2 then 1 else 0;      
    ghost var carry_new := if overflow(efl) then 1 else 0;
    //ghost var a0b := d0 + pow2_64 * d1 + pow2_128 * r12 + pow2_192 * r14 + pow2_256 * (rdx + carry);
    ghost var a0b := d0 + pow2_64 * d1 + pow2_128 * r12 + pow2_192 * r14 + pow2_256 * rax + pow2_320 * carry_new;

//    a0b_helper(a0, b0, b1, b2, b3, 
//               d0,      r9,
//               a0b1_lo, r11,
//               a0b2_lo, r13,
//               a0b3_lo, rdx,
//               d1, r12, r14,
//               overflow0, overflow1, overflow2);
//    assert a0 * b == a0b;   // PASSES 

    //assert_by_tactic(a0 * b == a0*b0 + pow2_64 * (a0*b1) + pow2_128 * (a0*b2) + pow2_192 * (a0*b3), int_canon);   // PASSES 
   // assert a0b == a0 * b;   // PASSES (with the assert_by_tactic above)
    //assert_by_tactic(a0b == a0 * b, int_canon);   // FAILS
//    assert rax == add_wrap64(rdx, carry);
//    assert overflow(efl) == rdx + carry >= pow2_64;
//    assert rax + pow2_64 * carry_new == rdx + carry;

//
//    "movq  8(A), %%rdx; " /* A[1] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[1]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 8(dst),  %%r8 ;"    "movq  %%r8,  8(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[1]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 16(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[1]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"                              "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[1]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"                              "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"

    Load64_buffer(rdx, inA_ptr,  8, Secret, inA_b, 1);     /* A[1] */
    lemma_load_mem64(inB_b, 0, mem);    // TODO: Why do I need to mention this again?!
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0, Secret));  /* A[1]*B[0] */ 
    assert pow2_64 * r9 + r8 == a1 * b0;
    Xor64(r10, r10);  ghost var a1b0_lo := r8;      Adcx64Wrap(r8, Mem(dst_ptr,  8, dst_b, 1, Secret));   Store64_buffer(dst_ptr, r8,  8, Secret, dst_b, 1);  // REVIEW: Why not combine the Adcx with the Store?
    lemma_load_mem64(inB_b, 1, mem);    // TODO: Why do I need to mention this again?!
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1, Secret));  /* A[1]*B[1] */ 
    assert pow2_64 * r11 + r10 == a1 * b1;
    Adox64Wrap(r10,  r9);  ghost var a1b1_lo := r10; ghost var mid_carry := if overflow(efl) then 1 else 0; Adcx64Wrap(r10, r12);                         Store64_buffer(dst_ptr, r10, 16, Secret, dst_b, 2); 
    lemma_load_mem64(inB_b, 2, mem);    // TODO: Why do I need to mention this again?!
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2, Secret));  /* A[1]*B[2] */ Adox64Wrap(r12, r11);  ghost var a1b2_lo := r12; Adcx64Wrap(r12, r14);                         Mov64( r8, 0); 
    lemma_load_mem64(inB_b, 3, mem);    // TODO: Why do I need to mention this again?!
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3, Secret));  /* A[1]*B[3] */ Adox64Wrap(r14, r13);  ghost var a1b3_lo := r14; Adcx64Wrap(r14, rax);                         Mov64(rax, 0);
    /*******************************************/                  Adox64Wrap(rax, rdx);  ghost var a1b_hi := rax;  carry_new := if overflow(efl) then 1 else 0;  Adcx64Wrap(rax, r8); 

//    ghost var a1b0b1 := a1b0_lo + pow2_64 * a1b1_lo + pow2_128 * (r11 + mid_carry);
//    assert_by_tactic(a1 * (b0 + pow2_64 * b1) == a1 * b0 + pow2_64 * (a1 * b1), int_canon);  // PASSES
//    assert a1b0b1 == a1 * (b0 + pow2_64 * b1);  // PASSES

    
    ghost var a1b := a1b0_lo + pow2_64 * a1b1_lo + pow2_128 * a1b2_lo + pow2_192 * a1b3_lo + pow2_256 * a1b_hi + pow2_320 * carry_new;
    assert_by_tactic(a1 * b == a1*b0 + pow2_64 * (a1*b1) + pow2_128 * (a1*b2) + pow2_192 * (a1*b3), int_canon);   // PASSES
    assert a1 * b == a1b;  // FAILS

//    d1 := buffer64_read(dst_b, 1, mem);
//    carry_new := if cf(efl) then 1 else 0;
//    ghost var overflow_new := if overflow(efl) then 1 else 0;
//    ghost var d2 := buffer64_read(dst_b, 2, mem);
//    ghost var a0a1b := d0 + pow2_64 * d1 + pow2_128 * d2 + pow2_192 * r12 + pow2_256 * r14 + pow2_320 * rax + pow2_384 * (carry_new + overflow_new);
//    //assert_by_tactic((a0 + pow2_64 * a1) * b == a0 * b + pow2_64 * (a1 * b), int_canon);                          // PASSES
//    //assert a0a1b == (a0 + pow2_64 * a1) * b;  // FAILS

/*


//
//    "movq 16(A), %%rdx; " /* A[2] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[2]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 16(dst), %%r8 ;"    "movq  %%r8, 16(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[2]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 24(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[2]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"                              "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[2]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"                              "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"

    Load64_buffer(rdx, inA_ptr, 16, Secret, inA_b, 2);     /* A[2] */
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0, Secret));  /* A[2]*B[0] */ Xor64(r10, r10);       Adcx64Wrap(r8, Mem(dst_ptr, 16, dst_b, 2, Secret));   Store64_buffer(dst_ptr,  r8, 16, Secret, dst_b, 2);
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1, Secret));  /* A[2]*B[1] */ Adox64Wrap(r10,  r9);  Adcx64Wrap(r10, r12);                         Store64_buffer(dst_ptr, r10, 24, Secret, dst_b, 3);
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2, Secret));  /* A[2]*B[2] */ Adox64Wrap(r12, r11);  Adcx64Wrap(r12, r14);                         Mov64( r8, 0);
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3, Secret));  /* A[2]*B[3] */ Adox64Wrap(r14, r13);  Adcx64Wrap(r14, rax);                         Mov64(rax, 0);
    /*******************************************/                  Adox64Wrap(rax, rdx);  Adcx64Wrap(rax, r8);

//
//    "movq 24(A), %%rdx; " /* A[3] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[3]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 24(dst), %%r8 ;"   "movq  %%r8, 24(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[3]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 32(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[3]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"    "movq %%r12, 40(dst) ;"    "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[3]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"    "movq %%r14, 48(dst) ;"    "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"    "movq %%rax, 56(dst) ;"

    Load64_buffer(rdx, inA_ptr, 24, Secret, inA_b, 3);     /* A[3] */
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0, Secret));  /* A[3]*B[0] */ Xor64(r10, r10);       Adcx64Wrap(r8, Mem(dst_ptr, 24, dst_b, 3, Secret));   Store64_buffer(dst_ptr,  r8, 24, Secret, dst_b, 3);
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1, Secret));  /* A[3]*B[1] */ Adox64Wrap(r10,  r9);  Adcx64Wrap(r10, r12);                         Store64_buffer(dst_ptr, r10, 32, Secret, dst_b, 4);

    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2, Secret));  /* A[3]*B[2] */ Adox64Wrap(r12, r11);  Adcx64Wrap(r12, r14);                         Store64_buffer(dst_ptr, r12, 40, Secret, dst_b, 5);   Mov64( r8, 0);
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3, Secret));  /* A[3]*B[3] */ Adox64Wrap(r14, r13);  Adcx64Wrap(r14, rax);                         Store64_buffer(dst_ptr, r14, 48, Secret, dst_b, 6);   Mov64(rax, 0);
    /*******************************************/                  Adox64Wrap(rax, rdx);  Adcx64Wrap(rax, r8);                          Store64_buffer(dst_ptr, rax, 56, Secret, dst_b, 7);

    assert_by_tactic(a*b == 
        a0 * b0 
      + pow2_64 * (a0 * b1 + b0 * a1)
      + pow2_128 * (a0 * b2 + a1 * b1 + a2 * b0)
      + pow2_192 * (a0 * b3 + a1 * b2 + a2 * b1 + a3 * b0)
      + pow2_256 * (a1 * b3 + a2 * b2 + a3 * b1)
      + pow2_320 * (a2 * b3 + a3 * b2)
      + pow2_384 * (a3 * b3), int_canon);       // PASSES

    d0 := buffer64_read(dst_b, 0, mem);
    d1 := buffer64_read(dst_b, 1, mem);
    ghost var d2 := buffer64_read(dst_b, 2, mem);
    ghost var d3 := buffer64_read(dst_b, 3, mem);
    ghost var d4 := buffer64_read(dst_b, 4, mem);
    ghost var d5 := buffer64_read(dst_b, 5, mem);
    ghost var d6 := buffer64_read(dst_b, 6, mem);
    ghost var d7 := buffer64_read(dst_b, 7, mem);
    ghost var d := d0 + pow2_64 * d1 + pow2_128 * d2 + pow2_192 * d3 +
                   pow2_256 * d4 + pow2_320 * d5 + pow2_384 * d6 + pow2_448 * d7;
    //assert d == a * b;  // FAILS
*/
}

/*
// fast_mul_stdcall(dst, inA, inB)
procedure{:quick} fast_mul_stdcall(
    inline win:bool,
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64,
    ghost stack_b:buffer64)
    lets
        dst_ptr @= rdi; inA_ptr @= rsi; inB_ptr @= rcx;
        dst_in := (if win then rcx else rdi);
        inA_in := (if win then rdx else rsi);
        inB_in := (if win then r8 else rdx);
    modifies
        rax; rbx; rcx; rdx; rdi; rsi; r8; r9; r10; r11; r12; r13; r14;
        rsp; efl; mem;
    requires
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        buffers_disjoint(stack_b, dst_b);
        buffers_disjoint(stack_b, inA_b);
        buffers_disjoint(stack_b, inB_b);

        validDstAddrs64(mem, dst_in, dst_b, 8);
        validSrcAddrs64(mem, inA_in, inA_b, 4);
        validSrcAddrs64(mem, inB_in, inB_b, 4);
        valid_stack_slots(mem, rsp, stack_b, 5, memTaint);
    ensures
        let a0 := buffer64_read(inA_b, 0, mem);
        let a1 := buffer64_read(inA_b, 1, mem);
        let a2 := buffer64_read(inA_b, 2, mem);
        let a3 := buffer64_read(inA_b, 3, mem);

        let b0 := buffer64_read(inB_b, 0, mem);
        let b1 := buffer64_read(inB_b, 1, mem);
        let b2 := buffer64_read(inB_b, 2, mem);
        let b3 := buffer64_read(inB_b, 3, mem);

        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        let d3 := buffer64_read(dst_b, 3, mem);
        let d4 := buffer64_read(dst_b, 4, mem);
        let d5 := buffer64_read(dst_b, 5, mem);
        let d6 := buffer64_read(dst_b, 6, mem);
        let d7 := buffer64_read(dst_b, 7, mem);

        let a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        let b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;

        let d := d0 + pow2_64 * d1 + pow2_128 * d2 + pow2_192 * d3 +
                 pow2_256 * d4 + pow2_320 * d5 + pow2_384 * d6 + pow2_448 * d7;
//        d == a * b;

        //////////////////////////////////////
        //   Framing
        //////////////////////////////////////

        modifies_buffer_2(dst_b, stack_b, old(mem), mem);
        validSrcAddrs64(mem, dst_in, dst_b, 8);

        rbx == old(rbx);
        rsi == old(rsi);
        r12 == old(r12);
        r13 == old(r13);
        r14 == old(r14);

        rsp == old(rsp);
{
    // Store callee-save registers
    Push(rbx, stack_b, 4);
    Push(rsi, stack_b, 3);
    Push(r12, stack_b, 2);
    Push(r13, stack_b, 1);
    Push(r14, stack_b, 0);

    // Line up the rest of the arguments
    inline if (win) {
        Mov64(dst_ptr, rcx);
        Mov64(inA_ptr, rdx);
        Mov64(inB_ptr, r8);
    } else {
        Mov64(inB_ptr, rdx);
    }

    fast_multiply(dst_b, inA_b, inB_b);

    Pop(r14, stack_b, 0);
    Pop(r13, stack_b, 1);
    Pop(r12, stack_b, 2);
    Pop(rsi, stack_b, 3);
    Pop(rbx, stack_b, 4);
}
*/
*/
