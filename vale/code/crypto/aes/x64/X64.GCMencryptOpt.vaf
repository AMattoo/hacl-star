include "../../../arch/x64/X64.Vale.InsBasic.vaf"
include "../../../arch/x64/X64.Vale.InsMem.vaf"
include "../../../arch/x64/X64.Vale.InsVector.vaf"
include "../../../lib/util/x64/X64.Stack.vaf"
include "../../../thirdPartyPorts/OpenSSL/aes/X64.AESGCM.vaf"
include "X64.AES.vaf"
include "X64.GF128_Mul.vaf"
include "X64.GCTR.vaf"
include "X64.GHash.vaf"
include{:fstar}{:open} "Prop_s"
include{:fstar}{:open} "open Opaque_s"
include{:/*TODO*/fstar}{:open} "FStar.Seq.Base"
include{:fstar}{:open} "Words_s"
include{:fstar}{:open} "Words.Seq_s"
include{:fstar}{:open} "Types_s"
include{:fstar}{:open} "Arch.Types"
include{:fstar}{:open} "AES_s"
include{:fstar}{:open} "GCTR_s"
include{:fstar}{:open} "GCTR"
include{:fstar}{:open} "GCM"
include{:fstar}{:open} "GHash_s"
include{:fstar}{:open} "GHash"
include{:fstar}{:open} "GCM_s"
include{:fstar}{:open} "GF128_s"
include{:fstar}{:open} "GF128"
include{:fstar}{:open} "Util.Meta"
include{:fstar}{:open} "X64.Poly1305.Math"
include{:fstar}{:open} "GCM_helpers"
include{:fstar}{:open} "Workarounds"
include{:fstar}{:open} "X64.Machine_s"
include{:fstar}{:open} "X64.Memory"
include{:fstar}{:open} "X64.Vale.State"
include{:fstar}{:open} "X64.Vale.Decls"
include{:fstar}{:open} "X64.Vale.QuickCode"
include{:fstar}{:open} "X64.Vale.QuickCodes"
include{:fstar}{:open} "X64.CPU_Features_s"

module X64.GCMencryptOpt

#verbatim{:interface}{:implementation}
module GHash = GHash
module GCTR = GCTR
open Prop_s
open Opaque_s
open FStar.Seq
open Words_s
open Words.Seq_s
open Types_s
open Arch.Types
open AES_s
open GCTR_s
open GCTR
open GCM
open GHash_s
open GHash
open GCM_s
open X64.AES
open GF128_s
open GF128
open X64.Poly1305.Math
open GCM_helpers
open Workarounds
open X64.GHash
open X64.GCTR
open X64.Machine_s
open X64.Memory
open X64.Vale.State
open X64.Vale.Decls
open X64.Vale.InsBasic
open X64.Vale.InsMem
open X64.Vale.InsVector
open X64.Vale.InsAes
open X64.Vale.QuickCode
open X64.Vale.QuickCodes
open X64.GF128_Mul
open X64.Stack
open X64.CPU_Features_s
open X64.AESGCM
open Util.Meta
#endverbatim

#verbatim{:interface}
let aes_reqs
  (alg:algorithm) (key:seq nat32) (round_keys:seq quad32) (keys_b:buffer128)
  (key_ptr:int) (mem:memory) (memTaint:memtaint) : prop0
  =
  aesni_enabled /\
  alg = AES_128 /\
  //(alg = AES_128 || alg = AES_256) /\
  is_aes_key_LE alg key /\
  length(round_keys) == nr(alg) + 1 /\
  round_keys == key_to_round_keys_LE alg key /\
  validSrcAddrs128 mem key_ptr keys_b (nr alg + 1) memTaint Secret /\
  buffer128_as_seq mem keys_b == round_keys
#endverbatim

function aes_reqs(alg:algorithm, key:seq(nat32), round_keys:seq(quad32), keys_b:buffer128,
    key_ptr:int, mem:memory, memTaint:memtaint) : prop extern;


///////////////////////////
// GCM
///////////////////////////
#reset-options "--z3rlimit 30"
procedure {:quick} gcm_blocks128(
    inline alg:algorithm,
    ghost in_b:buffer128,
    ghost out_b:buffer128,
    ghost key:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128
    )
    lets in_ptr @= rax; out_ptr @= rbx; len @= rcx; keys_ptr @= r8;
         icb @= xmm7; mask @= xmm8; hash @= xmm1; one @= xmm10; h @= xmm11;

    reads
        keys_ptr; in_ptr; out_ptr; len; mask; h; memTaint;

    modifies
        rdx; r9; r10; r12; xmm0; xmm1; xmm2; xmm3; xmm4; xmm5; xmm6; icb; one; mem; efl;

    requires
        // GCTR reqs
        buffers_disjoint128(keys_b, out_b);
        buffers_disjoint128(in_b, out_b) || in_b == out_b;
        validSrcAddrs128(mem,  in_ptr,  in_b, len, memTaint, Secret);
        validDstAddrs128(mem, out_ptr, out_b, len, memTaint, Secret);
        in_ptr  + 16 * len < pow2_64;
        out_ptr + 16 * len < pow2_64;
        buffer_length(in_b) == buffer_length(out_b) /\ 256 * buffer_length(in_b) < pow2_32;
        len == buffer_length(in_b);
        mask == Mkfour(0x0C0D0E0F, 0x08090A0B, 0x04050607, 0x00010203);

        // AES reqs
        aes_reqs(alg, key, round_keys, keys_b, keys_ptr, mem, memTaint);

        // GCM
        pclmulqdq_enabled;
    ensures
        modifies_buffer128(out_b, old(mem), mem);

        r9  ==  in_ptr + 16 * len;
        r10 == out_ptr + 16 * len;

        // GCTR
        gctr_partial(alg, len, old(buffer128_as_seq(mem, in_b)), buffer128_as_seq(mem, out_b), key, old(icb));
        icb == inc32(old(icb), old(len));

        // GHash
        len == 0 ==> hash == old(hash) /\ buffer128_as_seq(mem, out_b) == old(buffer128_as_seq(mem, out_b));
        len > 0 ==> length(slice_work_around(buffer128_as_seq(mem, out_b), len)) > 0 /\ 
                    hash == ghash_incremental(reverse_bytes_quad32(h), old(hash), buffer128_as_seq(mem, out_b));
{
    Mov64(rdx, 0);
    Mov64(r9, in_ptr);
    Mov64(r10, out_ptr);

    // Initialize counter increment
    ZeroXmm(one);
    PinsrdImm(one, 1, 0, r12);

    ghost var plain_quads:seq(quad32) := buffer128_as_seq(mem, in_b);

    while (rdx != len)
        invariant
            //////////////////// Basic indexing //////////////////////
            0 <= rdx <= len;
            r9 == in_ptr + 16 * rdx;
            r10 == out_ptr + 16 * rdx;
            icb == inc32(old(icb), rdx);

            //////////////////// From requires //////////////////////
            // GCTR reqs
            buffers_disjoint128(keys_b, out_b);
            buffers_disjoint128(in_b, out_b) || in_b == out_b;
            validSrcAddrs128(mem,  in_ptr,  in_b, len, memTaint, Secret);
            validDstAddrs128(mem, out_ptr, out_b, len, memTaint, Secret);
            in_ptr  + 16 * len < pow2_64;
            out_ptr + 16 * len < pow2_64;
            buffer_length(in_b) == buffer_length(out_b);
            rdx != len ==> partial_seq_agreement(plain_quads, buffer128_as_seq(mem, in_b), rdx, buffer_length(in_b));

            // AES reqs
            aes_reqs(alg, key, round_keys, keys_b, keys_ptr, mem, memTaint);

            pclmulqdq_enabled;
            //////////////////// GCTR invariants //////////////////////
            mask == Mkfour(0x0C0D0E0F, 0x08090A0B, 0x04050607, 0x00010203);
            one == Mkfour(1, 0, 0, 0);

            //////////////////// Postcondition goals //////////////////////
            modifies_buffer128(out_b, old(mem), mem);
            gctr_partial(alg, rdx, plain_quads, buffer128_as_seq(mem, out_b), key, old(icb));

            rdx == 0 ==> hash == old(hash) /\ buffer128_as_seq(mem, out_b) == old(buffer128_as_seq(mem, out_b));
            hash == ghash_incremental0(reverse_bytes_quad32(h), old(hash), slice_work_around(buffer128_as_seq(mem, out_b), rdx));
        decreases
            len - rdx;
    {
        ghost var snap := buffer128_as_seq(mem, in_b);
        Mov128(xmm0, icb);
        Pshufb(xmm0, mask);
        AESEncryptBlock(alg, reverse_bytes_quad32(icb), key, round_keys, keys_b);
        reveal aes_encrypt_LE_def;

        Load128_buffer(xmm2, r9, 0, Secret, in_b, rdx);
        Pxor(xmm2, xmm0);
        Store128_buffer(r10, xmm2, 0, Secret, out_b, rdx);

        // Update our hash
        ghost var hash_input := xmm2;
        ghost var hash_prev := hash;
        compute_ghash_incremental_register();
        lemma_hash_append2(reverse_bytes_quad32(h), old(hash), hash_prev, hash, slice_work_around(buffer128_as_seq(mem, out_b), rdx), hash_input);
        assert equal(slice_work_around(buffer128_as_seq(mem, out_b), rdx + 1), append(slice_work_around(buffer128_as_seq(mem, out_b), rdx), create(1, hash_input)));

        Add64(rdx, 1);
        Add64(r9, 16);
        Add64(r10, 16);
        Inc32(icb, one);
    }
}


procedure {:quick} gcm_auth_bytes(
    inline alg:algorithm,
    ghost auth_b:buffer128,
    ghost key:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128
    ) returns (
    ghost y_0:quad32,
    ghost y_auth:quad32
    )

    lets auth_ptr @= rax; keys_ptr @= r8; auth_num_bytes @= r11; 
         hash @= xmm1; mask @= xmm8; h128 @= xmm11; 

    reads
        keys_ptr; auth_num_bytes; mask; h128; mem; memTaint;

    modifies
        auth_ptr; rcx; rdx; r9; r12;
        xmm0; hash; xmm2; xmm3; xmm4; xmm5; xmm6; 
        efl;


    requires
        // GCM reqs
        validSrcAddrs128(mem, auth_ptr,  auth_b,  bytes_to_quad_size(auth_num_bytes), memTaint, Secret);
        auth_ptr  + 16 * bytes_to_quad_size(auth_num_bytes)  < pow2_64;
        buffer_length(auth_b) == bytes_to_quad_size(auth_num_bytes);
        4096 * auth_num_bytes < pow2_32;
        pclmulqdq_enabled;

        mask == Mkfour(0x0C0D0E0F, 0x08090A0B, 0x04050607, 0x00010203);
    ensures
        // Main result
        let auth   := slice_work_around(le_seq_quad32_to_bytes(buffer128_as_seq(old(mem), auth_b)),  old(auth_num_bytes));
        let auth_padded_bytes := pad_to_128_bits(auth);
        let auth_padded_quads := le_bytes_to_seq_quad32(auth_padded_bytes);

        y_0 == Mkfour(0, 0, 0, 0);
        y_auth == ghash_incremental0(reverse_bytes_quad32(old(h128)), y_0, auth_padded_quads);
        hash == y_auth;

        // Other intermediate facts
        auth_num_bytes == 0 ==> rdx == old(rdx) /\ r9 == old(r9);
{
    // Compute the hashes incrementally, starting with auth data
    ZeroXmm(hash);
    y_0 := Mkfour(0, 0, 0, 0);
    ghash_incremental_bytes(auth_b);
    y_auth := hash;
    le_bytes_to_seq_quad32_empty();
}

#reset-options "--z3rlimit 10"
procedure {:quick} gcm_make_length_quad()
    lets plain_num_bytes @= r13; auth_num_bytes @= r11; mask @= xmm8;
    reads plain_num_bytes; auth_num_bytes; mask;

    modifies xmm2; rax; efl;
    requires
        mask == Mkfour(0x0C0D0E0F, 0x08090A0B, 0x04050607, 0x00010203);
        plain_num_bytes * 8 < pow2_32;
        auth_num_bytes * 8 < pow2_32;
    ensures
        old(plain_num_bytes) * 8 < pow2_32;
        old(auth_num_bytes) * 8 < pow2_32;
        xmm2 == reverse_bytes_quad32(Mkfour(#nat32(8 * old(plain_num_bytes)), 0, #nat32(8 * old(auth_num_bytes)), 0));
{
    // Prepare length fields
    ZeroXmm(xmm2);
    Mov64(rax, plain_num_bytes);
    IMul64(rax, 8);
    Pinsrd(xmm2, rax, 0);
    Mov64(rax, auth_num_bytes);
    IMul64(rax, 8);
    Pinsrd(xmm2, rax, 2);
    Pshufb(xmm2, xmm8);
}

#reset-options "--z3rlimit 30"
procedure {:quick} {:verify true} gcm_blocks(
    inline alg:algorithm,
    ghost arg_b:buffer64,
    ghost auth_b:buffer128,
    ghost in128x6_b:buffer128,
    ghost out128x6_b:buffer128,
    ghost in128_b:buffer128,
    ghost out128_b:buffer128,
    ghost inout_b:buffer128,
    ghost iv_b:buffer128,
    ghost stack_b:buffer128,
    ghost key:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,
    ghost hkeys_b:buffer128
    )
    lets
        auth_ptr @= rdi; auth_num_bytes @= rsi; arg_ptr @= rdx; keys_ptr @= rcx; iv_ptr @= r8; Xip @= r9;

        in128x6_ptr     := buffer64_read(arg_b, 0, mem); 
        out128x6_ptr    := buffer64_read(arg_b, 1, mem); 
        len128x6        := buffer64_read(arg_b, 2, mem); 
        in128_ptr       := buffer64_read(arg_b, 3, mem); 
        out128_ptr      := buffer64_read(arg_b, 4, mem); 
        len128          := buffer64_read(arg_b, 5, mem); 
        inout_ptr       := buffer64_read(arg_b, 6, mem);
        plain_num_bytes := buffer64_read(arg_b, 7, mem);

//        in128x6_ptr @= rdi; out128x6_ptr @= rsi; len128x6 @= rdx; key_ptr @= rcx; iv_ptr @= r8; Xip @= r9;
//        in128_ptr @= rax; out128_ptr @= rbp; len128 @= r10; 
//        inout_ptr @= r15;

    reads
        //in128_ptr; out128_ptr; len128; inout_ptr; iv_ptr; rsp; 
        rsp; memTaint;

    modifies
        rax; rbx; rcx; rdx; rdi; rsi; rbp;
        r8; r9; r10; r11; r12; r13; r14; r15;
        xmm0; xmm1; xmm2; xmm3; xmm4; xmm5; xmm6; xmm7; xmm8; xmm9; xmm10; xmm11; xmm12; xmm13; xmm14; xmm15;
        mem; efl;

    requires
        // Valid buffers and pointers
// TODO: Handle auth values that aren't a multiple of 128-bits
        validSrcAddrs64 (mem,      arg_ptr,      arg_b,        8, memTaint, Public);
        validDstAddrs128(mem,     auth_ptr,     auth_b,  bytes_to_quad_size(auth_num_bytes), memTaint, Secret);
        validDstAddrs128(mem,       iv_ptr,       iv_b,        1, memTaint, Secret);
        validSrcAddrs128(mem,  in128x6_ptr,  in128x6_b, len128x6, memTaint, Secret);
        validDstAddrs128(mem, out128x6_ptr, out128x6_b, len128x6, memTaint, Secret);
        validSrcAddrs128(mem,    in128_ptr,    in128_b,   len128, memTaint, Secret);
        validDstAddrs128(mem,   out128_ptr,   out128_b,   len128, memTaint, Secret);
        validDstAddrs128(mem,    inout_ptr,    inout_b,        1, memTaint, Secret);
        validDstAddrs128(mem,          rsp,    stack_b,        8, memTaint, Secret);
        validSrcAddrs128(mem,          Xip,    hkeys_b,       10, memTaint, Secret);

//        buffer_length(stack_b) >= 30;       
//        valid_stack_slots(mem, rsp, stack_b, 30, memTaint);
//        valid_taint_buf64(stack_b, mem, memTaint, Secret);

        locs_disjoint(list(loc_buffer(iv_b), loc_buffer(arg_b)));
        buffers_disjoint128(iv_b, keys_b);
        buffers_disjoint128(iv_b, stack_b);
        buffers_disjoint128(iv_b, in128x6_b);
        buffers_disjoint128(iv_b, out128x6_b);
        buffers_disjoint128(iv_b, hkeys_b);
        buffers_disjoint128(iv_b, in128_b);
        buffers_disjoint128(iv_b, out128_b);
        buffers_disjoint128(iv_b, inout_b);
        locs_disjoint(list(loc_buffer(stack_b), loc_buffer(arg_b)));
        buffers_disjoint128(stack_b, keys_b);
        buffers_disjoint128(stack_b, in128x6_b);
        buffers_disjoint128(stack_b, out128x6_b);
        buffers_disjoint128(stack_b, in128_b);
        buffers_disjoint128(stack_b, out128_b);
        buffers_disjoint128(stack_b, inout_b);
        buffers_disjoint128(stack_b, hkeys_b);
        locs_disjoint(list(loc_buffer(out128x6_b), loc_buffer(arg_b)));
        buffers_disjoint128(out128x6_b, keys_b);
        buffers_disjoint128(out128x6_b, hkeys_b);
        locs_disjoint(list(loc_buffer(out128_b), loc_buffer(arg_b)));
        buffers_disjoint128(out128_b, keys_b);
        buffers_disjoint128(out128_b, hkeys_b);
        buffers_disjoint128(out128_b, out128x6_b);
        locs_disjoint(list(loc_buffer(inout_b), loc_buffer(arg_b)));
        buffers_disjoint128(inout_b, keys_b);
        buffers_disjoint128(inout_b, hkeys_b);
        buffers_disjoint128(inout_b, out128x6_b);
        buffers_disjoint128(inout_b, out128_b);
        buffers_disjoint128(in128x6_b, out128x6_b) || in128x6_b == out128x6_b;
        buffers_disjoint128(in128_b, out128_b) || in128_b == out128_b;

        auth_ptr  + 16 * bytes_to_quad_size(auth_num_bytes)  < pow2_64;
         in128x6_ptr + 0x10*len128x6 < pow2_64;
        out128x6_ptr + 0x10*len128x6 < pow2_64;
           in128_ptr + 0x10*len128   < pow2_64;
          out128_ptr + 0x10*len128   < pow2_64;
           inout_ptr + 0x10          < pow2_64;

        buffer_length(auth_b) == bytes_to_quad_size(auth_num_bytes);
        buffer_length(in128x6_b) == buffer_length(out128x6_b);
        buffer_length(in128_b) == buffer_length(out128_b);
        buffer_length(in128x6_b) == len128x6;
        buffer_length(in128_b) == len128;
        buffer_length(inout_b) == 1;
        8 * plain_num_bytes < pow2_32;
        4096 * (buffer_length(in128x6_b)) * 16 < pow2_32;
        256 * buffer_length(in128_b) < pow2_32;
        4096 * auth_num_bytes < pow2_32;
        Xip + 0x20 < pow2_64;

        buffer_addr(keys_b, mem) + 0x80 < pow2_64;

        // len128x6 is # of 128-bit blocks that come in 6-block chunks
        len128x6 % 6 == 0;
        len128x6 >= 18;
        //len128x6 / 6 >= 3;   // Should be implied by above... :(
        12 + len128x6 + 6 < pow2_32;

        // GCTR reqs
        aes_reqs(alg, key, round_keys, keys_b, keys_ptr, mem, memTaint);

        // GCM reqs
        pclmulqdq_enabled;


    ensures
//        modifies_buffer128(out_b, old(mem), mem);
//        validSrcAddrsOffset128(mem, out_ptr, out_b, block_offset, len, memTaint, Secret);

//        r9  ==  in128x6_ptr + 16 * len;
//        r10 == out128x6_ptr + 16 * len;

        // GCTR results
//        gctr_partial_opaque(alg, old(len128x6), old(buffer128_as_seq(mem, in128x6_b)), buffer128_as_seq(mem, out128x6_b), key, buffer128_read(iv_b, 0, mem));
        // GCM results
        //hash == ghash_incremental(reverse_bytes_quad32(h), old(hash), buffer128_as_seq(mem, out_b), old(len));
        8 * old(plain_num_bytes) < pow2_32;
        8 * old(auth_num_bytes) < pow2_32;
        let h := reverse_bytes_quad32(buffer128_read(hkeys_b, 0, mem));
        let auth := slice_work_around(le_seq_quad32_to_bytes(buffer128_as_seq(old(mem), auth_b)),  old(auth_num_bytes));
        let auth_padded_bytes := pad_to_128_bits(auth);
        let auth_padded_quads := le_bytes_to_seq_quad32(auth_padded_bytes);
        let length_quad := reverse_bytes_quad32(Mkfour(#nat32(8 * old(plain_num_bytes)), 0, 
                                                       #nat32(8 * old(auth_num_bytes)), 0));
        let auth_in := append(
                       append(
                       append(
                       append(auth_padded_quads, 
                              buffer128_as_seq(mem, out128x6_b)),
                              buffer128_as_seq(mem, out128_b)),
                              buffer128_as_seq(mem, inout_b)),
                              create(1, length_quad));
        let iv_LE := old(buffer128_read(iv_b, 0, mem));
        let iv_BE := reverse_bytes_quad32(iv_LE);
        let ctr_BE_1:quad32 := Mkfour(1, iv_BE.lo1, iv_BE.hi2, iv_BE.hi3);
        xmm1 == gctr_encrypt_block(ctr_BE_1, ghash_LE(h, #ghash_plain_LE(auth_in)), alg, key, 0);
{
    // Preserve arguments that gcm_auth_bytes will clobber
    Mov64(rbp, arg_ptr);
    Mov64(r13, iv_ptr);
    Mov64(r14, Xip);

    // Line up the arguments for gcm_auth_bytes
    InitPshufbMask(xmm8, r12);
    Mov64(rax, auth_ptr);
    Mov64(r8, keys_ptr);
    Mov64(r11, auth_num_bytes);
    Load128_buffer(xmm11, Xip, 0, Secret, hkeys_b, 0); // Load h instead of computing it

    (ghost var y_0), (ghost var y_auth) := gcm_auth_bytes(alg, auth_b, key, round_keys, keys_b);
    ghost var auth   := slice_work_around(le_seq_quad32_to_bytes(buffer128_as_seq(old(mem), auth_b)),  old(auth_num_bytes));
    ghost var auth_padded_bytes := pad_to_128_bits(auth);
    ghost var auth_padded_quads := le_bytes_to_seq_quad32(auth_padded_bytes);

    // Save auth_num_bytes, since AES_GCM_encrypt_6mult will clobber it
    Mov64(r15, auth_num_bytes);

    // Line up the arguments for AES_GCM_encrypt_6mult
    Load64_buffer(rdi, rbp,  0, Public, arg_b, 0);
    Load64_buffer(rsi, rbp,  8, Public, arg_b, 1);
    Load64_buffer(rdx, rbp, 16, Public, arg_b, 2);
    Mov64(keys_ptr, r8);
    Mov64(iv_ptr, r13);
    Mov64(Xip, r14);
    Mov128(xmm8, xmm1); // Line up the intermediate hash value

    (ghost var ctr_BE) := AES_GCM_encrypt_6mult(alg, iv_b, in128x6_b, out128x6_b, stack_b, key, round_keys, keys_b, hkeys_b);
    ghost var y_cipher128x6 := xmm8;

    // Line up arguments for gcm_blocks128 for remaining 128-bit blocks
    Load128_buffer(xmm7, iv_ptr, 0, Secret, iv_b, 0);
    Mov64(r8, keys_ptr);
    Load64_buffer(rax, rbp, 24, Public, arg_b, 3);
    Load64_buffer(rbx, rbp, 32, Public, arg_b, 4);
    Load64_buffer(rcx, rbp, 40, Public, arg_b, 5);
    Mov128(xmm1, xmm8);     // Move the hash value into the right place
    InitPshufbMask(xmm8, r12);
    Pshufb(xmm7, xmm8);
    Load128_buffer(xmm11, Xip, 0 - 0x20, Secret, hkeys_b, 0); 

    gcm_blocks128(alg, in128_b, out128_b, key, round_keys, keys_b);
    ghost var y_cipher128 := xmm1;

    // Line up arguments for gcm_blocks128 for the 128-bit block that holds any extra bytes
    Load64_buffer(rax, rbp, 48, Public, arg_b, 6);
    Mov64(rbx, rax);
    Mov64(rcx, 1);
    gcm_blocks128(alg, inout_b, inout_b, key, round_keys, keys_b);
    ghost var y_inout := xmm1;

    // Line up length arguments
    Load64_buffer(r13, rbp, 56, Public, arg_b, 7);
    Mov64(r11, r15);
    gcm_make_length_quad();
    ghost var length_quad32 := xmm2;

    compute_ghash_incremental_register();
    ghost var y_final := xmm1;

    PinsrdImm(xmm7, 1, 0, r12);   // Reconstruct j0 (this is all we need, since gctr_core says it only changes iv.lo0)
    ghost var ctr_BE_1:quad32 := Mkfour(1, ctr_BE.lo1, ctr_BE.hi2, ctr_BE.hi3); 
    assert_norm(xmm7 == ctr_BE_1);      // OBSERVE

    // Encrypt the hash value with gctr_register; result goes in xmm1
    gctr_register(alg, key, round_keys, keys_b); // Encrypt using j0 and xmm0 = hash_value

    le_seq_quad32_to_bytes_of_singleton(xmm1);

    // Consolidate hashing results
    ghost var h := reverse_bytes_quad32(buffer128_read(hkeys_b, 0, mem));
    ghost var auth_in := auth_padded_quads;
    lemma_ghash_incremental0_append(h, y_0, y_auth, y_cipher128x6, auth_in, buffer128_as_seq(mem, out128x6_b));
    auth_in := append(auth_in, buffer128_as_seq(mem, out128x6_b));
    lemma_ghash_incremental0_append(h, y_0, y_cipher128x6, y_cipher128, auth_in, buffer128_as_seq(mem, out128_b));
    auth_in := append(auth_in, buffer128_as_seq(mem, out128_b));
    lemma_ghash_incremental0_append(h, y_0, y_cipher128, y_inout, auth_in, buffer128_as_seq(mem, inout_b));
    auth_in := append(auth_in, buffer128_as_seq(mem, inout_b));

    lemma_hash_append2(h, y_0, y_inout, y_final, auth_in, length_quad32);
    auth_in := append(auth_in, create(1, length_quad32));
    ghash_incremental_to_ghash(h, auth_in);
}

