include "../../../arch/x64/X64.Vale.InsBasic.vaf"
include "../../../arch/x64/X64.Vale.InsMem.vaf"
include "../../../arch/x64/X64.Vale.InsVector.vaf"
include "../../../arch/x64/X64.Vale.InsAes.vaf"
include{:fstar}{:open} "Prop_s"
include{:fstar}{:open} "Opaque_s"
include{:fstar}{:open} "Words_s"
include{:fstar}{:open} "Types_s"
include{:/*TODO*/fstar}{:open} "FStar.Seq.Base"
include{:fstar}{:open} "AES_s"
include{:fstar}{:open} "X64.Machine_s"
include{:fstar}{:open} "X64.Memory"
include{:fstar}{:open} "X64.Vale.State"
include{:fstar}{:open} "X64.Vale.Decls"
include{:fstar}{:open} "X64.Vale.QuickCode"
include{:fstar}{:open} "X64.Vale.QuickCodes"
include{:fstar}{:open} "Arch.Types"
include{:fstar}{:open} "AES_helpers"
include{:fstar}{:open} "X64.Poly1305.Math"
include{:fstar}{:open} "GCM_helpers"
include{:fstar}{:open} "Workarounds"
include{:fstar}{:open} "GCTR_s"
include{:fstar}{:open} "GCTR"
include{:fstar}{:open} "Arch.TypesNative"
include{:fstar}{:open} "X64.CPU_Features_s"

module X64.AESopt

#verbatim{:interface}{:implementation}
open Prop_s
open Opaque_s
open Words_s
open Types_s
open FStar.Seq
open AES_s
open X64.Machine_s
open X64.Memory
open X64.Vale.State
open X64.Vale.Decls
open X64.Vale.InsBasic
open X64.Vale.InsMem
open X64.Vale.InsVector
open X64.Vale.InsAes
open X64.Vale.QuickCode
open X64.Vale.QuickCodes
open Arch.Types
open AES_helpers
open X64.Poly1305.Math    // For lemma_poly_bits64()
open GCM_helpers
open Workarounds
open GCTR_s
open GCTR
open Arch.TypesNative
open X64.CPU_Features_s
#endverbatim

#verbatim{:interface}
let aes_reqs
  (alg:algorithm) (key:seq nat32) (round_keys:seq quad32) (keys_b:buffer128)
  (key_ptr:nat64) (mem:memory) (memTaint:memtaint) : prop0
  =
  aesni_enabled /\
  alg = AES_128 /\
  //(alg = AES_128 || alg = AES_256) /\
  is_aes_key_LE alg key /\
  length(round_keys) == nr(alg) + 1 /\
  round_keys == key_to_round_keys_LE alg key /\

  //validSrcAddrsOffset128 mem key_ptr keys_b 8 (nr alg + 1) memTaint Secret /\
  // Can't use the standard Offset, since that makes the size too large and conflicts
  // with the spec below that says the entire keys_b is exactly round_keys
  buffer_readable mem keys_b /\
  (nr alg + 1) <= buffer_length keys_b /\
  buffer_addr keys_b mem + 16 `op_Multiply` 8 == key_ptr /\
  valid_taint_buf128 keys_b mem memTaint Secret /\

  buffer128_as_seq mem keys_b == round_keys
#endverbatim
function aes_reqs(alg:algorithm, key:seq(nat32), round_keys:seq(quad32), keys_b:buffer128,
    key_ptr:nat64, mem:memory, memTaint:memtaint) : prop extern;

ghost procedure finish_aes_encrypt_le(ghost alg:algorithm, ghost input_LE:quad32, ghost key:seq(nat32))
    requires
        is_aes_key_LE(alg, key);
    ensures
        aes_encrypt_le(alg, key, input_LE) == cipher_opaque(alg, input_LE, key_to_round_keys_LE(alg, key));
{
    reveal aes_encrypt_LE_def;
    reveal cipher;
}

procedure {:quick exportOnly} load_two_lsb(inout dst:xmm)
    lets constp @= r11; 
    modifies constp; efl;
    ensures  dst == Mkfour(2, 0, 0, 0);
{
    ZeroXmm(dst);
    lemma_insert_nat64_nat32s(dst, 2, 0);
    assert two_to_nat32(Mktwo(2, 0)) == 0x2; // OBSERVE
    PinsrqImm(dst, 2, 0, constp);
}

// Version with concrete values succeeds.
//procedure {:quick} load_one_lsb()
//    lets constp @= r11; dst @= xmm1;
//    modifies constp; dst; efl;
//    ensures  dst == Mkfour(1, 0, 0, 0);
//{
//    ZeroXmm(dst);
//    assert two_to_nat32(Mktwo(1, 0)) == 0x1; // OBSERVE
//    PinsrqImm(dst, 1, 0, constp);
//    reveal insert_nat64;
//}

procedure {:quick exportOnly} load_one_lsb(inout dst:xmm)
    lets constp @= r11; 
    modifies constp; efl;
    //ensures  dst == Mkfour(1, 0, 0, 0);
{
    ZeroXmm(dst);
    lemma_insert_nat64_nat32s(dst, 1, 0);
    assert two_to_nat32(Mktwo(1, 0)) == 0x1; // OBSERVE
    PinsrqImm(dst, 1, 0, constp);
}

#reset-options "--z3rlimit 20"
procedure {:quick} handle_ctr32(
    ghost ctr_BE:quad32
    )
    lets
        Ii @= xmm0; T1 @= xmm1; T2 @= xmm2;
        Z1 @= xmm5; Z2 @= xmm6; 
        inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
        constp @= r11;
    reads
        rndkey;

    modifies
        constp;
        Ii; T1; T2; Z1; Z2; inout1; inout2; inout3; inout4; inout5; 
        efl;

    requires
        T1 == reverse_bytes_quad32(ctr_BE);
    ensures
        inout1 == quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 1)), rndkey);
        inout2 == quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 2)), rndkey);
        inout3 ==            reverse_bytes_quad32(inc32(ctr_BE, 3));
        inout4 ==            reverse_bytes_quad32(inc32(ctr_BE, 4));
        inout5 ==            reverse_bytes_quad32(inc32(ctr_BE, 5));
        T1     ==            reverse_bytes_quad32(inc32(ctr_BE, 6));
{
    InitPshufbMask(Ii, constp);  // # borrow $Ii for .Lbswap_mask
    VPshufb(Z2, T1, Ii);         // # byte-swap counter
    // OpenSSL uses a memory operand with VPaddd to do the addition with .Lone_lsb.  We avoid that here for now.
    //load_two_lsb();              // # borrow $Z1, .Ltwo_lsb
    //load_one_lsb();              // # .Lone_lsb
    load_one_lsb(Z1);
    VPaddd(inout1, Z2, Z1);
    load_two_lsb(Z1);              
    VPaddd(inout2, Z2, Z1);
    VPaddd(inout3, inout1, Z1);
    VPshufb(inout1, inout1, Ii);
    VPaddd(inout4, inout2, Z1);
    VPshufb(inout2, inout2, Ii);
    VPxor(inout1, inout1, rndkey);
    VPaddd(inout5, inout3, Z1);
    VPshufb(inout3, inout3, Ii);
    VPxor(inout2, inout2, rndkey);
    VPaddd(T1, inout4, Z1);         // # byte-swapped next counter value
    VPshufb(inout4, inout4, Ii);
    VPshufb(inout5, inout5, Ii);
    VPshufb(T1, T1, Ii);            // # next counter value
}

#reset-options ""
procedure {:quick} loop6x_ctr_update(
    inline alg:algorithm,  
    ghost key_words:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,

    ghost ctr_BE:quad32
    )
    lets
//      inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        key @= rcx; 
        Ii @= xmm0; T1 @= xmm1; T2 @= xmm2;
        Z1 @= xmm5; Z2 @= xmm6; 
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;
        counter @= rbx; constp @= r11; 
    reads
        key; rndkey;

    modifies
        counter; constp;
        Ii; T1; T2; Z1; Z2; inout0; inout1; inout2; inout3; inout4; inout5; 
        efl;

    requires
        // AES reqs
        aes_reqs(alg, key_words, round_keys, keys_b, key, mem, memTaint);
        //rndkey == index(round_keys, 0);

        // Counter requirements
        T2 == Mkfour(0, 0, 0, 0x1000000);

        T1 == reverse_bytes_quad32(inc32(ctr_BE, 0));
        //0 <= counter < 256;  // Implied by next line
        counter == ctr_BE.lo0 % 256;

        //inout5.hi3 + 0x1000000 < pow2_32;

        inout0 == quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 0)), rndkey);   

        counter + 6 < 256 ==> inout1 == reverse_bytes_quad32(inc32(ctr_BE, 1));
        counter + 6 < 256 ==> inout2 == reverse_bytes_quad32(inc32(ctr_BE, 2));
        counter + 6 < 256 ==> inout3 == reverse_bytes_quad32(inc32(ctr_BE, 3));
        counter + 6 < 256 ==> inout4 == reverse_bytes_quad32(inc32(ctr_BE, 4));
        counter + 6 < 256 ==> inout5 == reverse_bytes_quad32(inc32(ctr_BE, 5));
    ensures
        T1 == reverse_bytes_quad32(inc32(ctr_BE, 6));
        0 <= counter < 256;
        counter == inc32(ctr_BE, 6).lo0 % 256;

        inout0 == quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 0)), rndkey);
        inout1 == quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 1)), rndkey);
        inout2 == quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 2)), rndkey);

        inout3 == reverse_bytes_quad32(inc32(ctr_BE, 3));
        inout4 == reverse_bytes_quad32(inc32(ctr_BE, 4));
        inout5 == reverse_bytes_quad32(inc32(ctr_BE, 5));
{
    // OpenSSL does this with "add `6<<24`,counter", followed by jc, 
    // which handles wrap and control flow more efficiently
    Add64(counter, 6);      
    if (counter >= 256) {
        handle_ctr32(ctr_BE); //, counter);
        Sub64(counter, 256);
    } else {
        VPaddd(T1, T2, inout5); // OpenSSL uses VPaddb
        VPxor(inout1, inout1, rndkey); 
        VPxor(inout2, inout2, rndkey); 
        lemma_msb_in_bounds(ctr_BE, inout5, T1, old(counter));
    }
}

procedure {:quick} loop6x_preamble(
    inline alg:algorithm,  // OpenSSL includes the number of rounds (nr) as a dynamic parameter (stored with the key).  Saves code space but adds extra instructions to the fast path.  Maybe branch predictor is good enough for it not to matter
    ghost iv_b:buffer128,

    ghost key_words:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,

    ghost ctr_BE:quad32
    )
    lets
//      inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        key @= rcx; ivp @= r8; 
        Ii @= xmm0; T1 @= xmm1; T2 @= xmm2;
        Z1 @= xmm5; Z2 @= xmm6; 
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;
        counter @= rbx; constp @= r11; 
    reads
        key; ivp;
        rndkey;
        memTaint;

    modifies
        counter; constp;
        Ii; T1; T2; Z1; Z2; inout0; inout1; inout2; inout3; inout4; inout5; 
        mem; efl;

    requires
        // Valid ptrs and buffers
        validDstAddrs128(mem, ivp, iv_b, 1, memTaint, Secret);
        buffers_disjoint128(iv_b, keys_b);

        // AES reqs
        aes_reqs(alg, key_words, round_keys, keys_b, key, mem, memTaint);
        rndkey == index(round_keys, 0);

        // Counter requirements
        T2 == Mkfour(0, 0, 0, 0x1000000);

        T1 == reverse_bytes_quad32(inc32(ctr_BE, 0));
        counter == ctr_BE.lo0 % 256;

        inout0 == quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 0)), rndkey);   

        counter + 6 < 256 ==> inout1 == reverse_bytes_quad32(inc32(ctr_BE, 1));
        counter + 6 < 256 ==> inout2 == reverse_bytes_quad32(inc32(ctr_BE, 2));
        counter + 6 < 256 ==> inout3 == reverse_bytes_quad32(inc32(ctr_BE, 3));
        counter + 6 < 256 ==> inout4 == reverse_bytes_quad32(inc32(ctr_BE, 4));
        counter + 6 < 256 ==> inout5 == reverse_bytes_quad32(inc32(ctr_BE, 5));


        //inout0 == quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 0)), rndkey);   
//        inout1 ==            reverse_bytes_quad32(inc32(ctr_BE, 1));
//        inout2 ==            reverse_bytes_quad32(inc32(ctr_BE, 2));
//        inout3 ==            reverse_bytes_quad32(inc32(ctr_BE, 3));
//        inout4 ==            reverse_bytes_quad32(inc32(ctr_BE, 4));
//        inout5 ==            reverse_bytes_quad32(inc32(ctr_BE, 5));
    ensures
        // Framing
        modifies_buffer128(iv_b, old(mem), mem);

        // Semantics

        // IO
        inout0 == rounds_opaque(old(inout0), round_keys, 1);
        inout1 == rounds_opaque(quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 1)), rndkey), round_keys, 1);
        inout2 == rounds_opaque(quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 2)), rndkey), round_keys, 1);
        inout3 == rounds_opaque(quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 3)), rndkey), round_keys, 1);
        inout4 == rounds_opaque(quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 4)), rndkey), round_keys, 1);
        inout5 == rounds_opaque(quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 5)), rndkey), round_keys, 1);

        // Next counter
        buffer128_read(iv_b, 0, mem) == reverse_bytes_quad32(inc32(ctr_BE, 6));

        // Counter details
        0 <= counter < 256;
        //counter == (ctr_BE.lo0 + 6) % 256;
        counter == inc32(ctr_BE, 6).lo0 % 256;
{
    loop6x_ctr_update(alg, key_words, round_keys, keys_b, ctr_BE);

    init_rounds_opaque(inout0, round_keys);
    init_rounds_opaque(inout1, round_keys);
    init_rounds_opaque(inout2, round_keys);

    /*
    init_rounds_opaque(inout0, round_keys);

    if (key > 72) {         // TODO: FIX!
        handle_ctr32(ctr_BE);
    } else {
        VPaddd(T1, T2, inout5); // OpenSSL uses VPaddb
        VPxor(inout1, inout1, rndkey); 
        VPxor(inout2, inout2, rndkey); 
        lemma_incr_msb(inc32(ctr_BE, 5), old(inout5), T1, 1);
    }
    init_rounds_opaque(inout1, round_keys);
    init_rounds_opaque(inout2, round_keys);
    */

    Store128_buffer(ivp, T1, 0, Secret, iv_b, 0);   // # save next counter value
    VPxor(inout3, inout3, rndkey); init_rounds_opaque(inout3, round_keys);
    Load128_buffer(T2, key, 0x10-0x80, Secret, keys_b, 1); // # borrow $T2 for $rndkey

    VAESNI_enc(inout0, inout0, T2);
    VPxor(inout4, inout4, rndkey); init_rounds_opaque(inout4, round_keys);
    VAESNI_enc(inout1, inout1, T2);
    VPxor(inout5, inout5, rndkey); init_rounds_opaque(inout5, round_keys);
    VAESNI_enc(inout2, inout2, T2);
    VAESNI_enc(inout3, inout3, T2);
    VAESNI_enc(inout4, inout4, T2);
    //Load128_buffer(rndkey, key, 0x20-0x80, Secret, keys_b, 2);      // OpenSSL had this here.  I moved it to one of the loop6x_step calls
    VAESNI_enc(inout5, inout5, T2);

    reveal rounds;
    commute_sub_bytes_shift_rows_forall();

}

#reset-options ""

procedure {:quick} loop6x_plain(
    inline alg:algorithm,  // OpenSSL includes the number of rounds (nr) as a dynamic parameter (stored with the key).  Saves code space but adds extra instructions to the fast path.  Maybe branch predictor is good enough for it not to matter
    inline rnd:nat,
    ghost key_words:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,

    ghost init0:quad32,
    ghost init1:quad32,
    ghost init2:quad32,
    ghost init3:quad32,
    ghost init4:quad32,
    ghost init5:quad32
    )
    lets
//      inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        key @= rcx; 
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;

    reads
        key; 
        mem; memTaint;

    modifies
        inout0; inout1; inout2; inout3; inout4; inout5; rndkey;
        efl;

    requires
        // AES reqs
        aes_reqs(alg, key_words, round_keys, keys_b, key, mem, memTaint);
        rnd + 1 < length(round_keys);

        inout0 == rounds_opaque(init0, round_keys, rnd);
        inout1 == rounds_opaque(init1, round_keys, rnd);
        inout2 == rounds_opaque(init2, round_keys, rnd);
        inout3 == rounds_opaque(init3, round_keys, rnd);
        inout4 == rounds_opaque(init4, round_keys, rnd);
        inout5 == rounds_opaque(init5, round_keys, rnd);

    ensures
        inout0 == rounds_opaque(init0, round_keys, rnd + 1);
        inout1 == rounds_opaque(init1, round_keys, rnd + 1);
        inout2 == rounds_opaque(init2, round_keys, rnd + 1);
        inout3 == rounds_opaque(init3, round_keys, rnd + 1);
        inout4 == rounds_opaque(init4, round_keys, rnd + 1);
        inout5 == rounds_opaque(init5, round_keys, rnd + 1);
{
    Load128_buffer(rndkey, key, 16*(rnd+1)-0x80, Secret, keys_b, rnd+1);

    VAESNI_enc(inout0, inout0, rndkey);
    VAESNI_enc(inout1, inout1, rndkey);
    VAESNI_enc(inout2, inout2, rndkey);
    VAESNI_enc(inout3, inout3, rndkey);
    VAESNI_enc(inout4, inout4, rndkey);
    VAESNI_enc(inout5, inout5, rndkey);

    reveal rounds;
    commute_sub_bytes_shift_rows_forall();
}


procedure {:quick} loop6x_step(
    inline alg:algorithm,  // OpenSSL includes the number of rounds (nr) as a dynamic parameter (stored with the key).  Saves code space but adds extra instructions to the fast path.  Maybe branch predictor is good enough for it not to matter
    inline rnd:nat,
    inline in0_offset:nat,
    inline stack_offset:nat,
    ghost in0_b:buffer128,
    ghost stack_b:buffer128,

    ghost key_words:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,

    ghost init0:quad32,
    ghost init1:quad32,
    ghost init2:quad32,
    ghost init3:quad32,
    ghost init4:quad32,
    ghost init5:quad32
    )
    lets
//      inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        key @= rcx; 
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;
        in0 @= r14; 

    reads
        key; rsp; in0;
        memTaint;

    modifies
        r12; r13; 
        inout0; inout1; inout2; inout3; inout4; inout5; rndkey;
        mem; efl;

    requires
        // Valid ptrs and buffers
        validSrcAddrs128(mem, in0, in0_b, in0_offset + 1, memTaint, Secret);
        validDstAddrs128(mem, rsp, stack_b, stack_offset + 1, memTaint, Secret);

        // AES reqs
        aes_reqs(alg, key_words, round_keys, keys_b, key, mem, memTaint);
        rnd + 1 < length(round_keys);

        inout0 == rounds_opaque(init0, round_keys, rnd);
        inout1 == rounds_opaque(init1, round_keys, rnd);
        inout2 == rounds_opaque(init2, round_keys, rnd);
        inout3 == rounds_opaque(init3, round_keys, rnd);
        inout4 == rounds_opaque(init4, round_keys, rnd);
        inout5 == rounds_opaque(init5, round_keys, rnd);

    ensures
        // Framing
        modifies_buffer_specific128(stack_b, old(mem), mem, stack_offset, stack_offset + 1);

        // Semantics
        inout0 == rounds_opaque(init0, round_keys, rnd + 1);
        inout1 == rounds_opaque(init1, round_keys, rnd + 1);
        inout2 == rounds_opaque(init2, round_keys, rnd + 1);
        inout3 == rounds_opaque(init3, round_keys, rnd + 1);
        inout4 == rounds_opaque(init4, round_keys, rnd + 1);
        inout5 == rounds_opaque(init5, round_keys, rnd + 1);

        buffer128_read(stack_b, stack_offset, mem) == old(reverse_bytes_quad32(buffer128_read(in0_b, in0_offset, mem)));
{
    Load128_buffer(rndkey, key, (0x10 * (rnd + 1))-0x80, Secret, keys_b, rnd + 1);

    VAESNI_enc(inout0, inout0, rndkey);
    VAESNI_enc(inout1, inout1, rndkey);

    LoadBe64_buffer128(r13, in0, in0_offset*16+8, Secret, true,  in0_b, in0_offset);

    VAESNI_enc(inout2, inout2, rndkey);

    LoadBe64_buffer128(r12, in0, in0_offset*16,   Secret, false, in0_b, in0_offset);

    VAESNI_enc(inout3, inout3, rndkey);

    Store64_buffer128(rsp, r13, stack_offset*16,   Secret, false, stack_b, stack_offset);  // OpenSSL is further offset by 8 (to account for return addr?)

    VAESNI_enc(inout4, inout4, rndkey);

    Store64_buffer128(rsp, r12, stack_offset*16+8, Secret, true,  stack_b, stack_offset);   // OpenSSL is further offset by 8 (to account for return addr?)

    VAESNI_enc(inout5, inout5, rndkey);

    reveal rounds;
    commute_sub_bytes_shift_rows_forall();
    lemma_reverse_bytes_quad32_64(old(buffer128_read(in0_b, in0_offset, mem)), old(buffer128_read(stack_b, stack_offset, mem)), buffer128_read(stack_b, stack_offset, mem));

}


procedure {:quick} loop6x_round8(
    inline alg:algorithm,  // OpenSSL includes the number of rounds (nr) as a dynamic parameter (stored with the key).  Saves code space but adds extra instructions to the fast path.  Maybe branch predictor is good enough for it not to matter
    ghost in0_b:buffer128,
    ghost stack_b:buffer128,

    ghost key_words:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,

    ghost init0:quad32,
    ghost init1:quad32,
    ghost init2:quad32,
    ghost init3:quad32,
    ghost init4:quad32,
    ghost init5:quad32
    )
    lets
//      inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        key @= rcx; 
        T1 @= xmm1; T2 @= xmm2; 
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;
        in0 @= r14; 

    reads
        key; in0;
        mem; memTaint;

    modifies
        r12; r13; 
        T1; T2; inout0; inout1; inout2; inout3; inout4; inout5; rndkey;
        efl;

    requires
        // Valid ptrs and buffers
        validSrcAddrs128(mem, in0, in0_b, 1, memTaint, Secret);

        // AES reqs
        aes_reqs(alg, key_words, round_keys, keys_b, key, mem, memTaint);

        inout0 == rounds_opaque(init0, round_keys, 7);
        inout1 == rounds_opaque(init1, round_keys, 7);
        inout2 == rounds_opaque(init2, round_keys, 7);
        inout3 == rounds_opaque(init3, round_keys, 7);
        inout4 == rounds_opaque(init4, round_keys, 7);
        inout5 == rounds_opaque(init5, round_keys, 7);

    ensures
        // Semantics
        inout0 == rounds_opaque(init0, round_keys, 8);
        inout1 == rounds_opaque(init1, round_keys, 8);
        inout2 == rounds_opaque(init2, round_keys, 8);
        inout3 == rounds_opaque(init3, round_keys, 8);
        inout4 == rounds_opaque(init4, round_keys, 8);
        inout5 == rounds_opaque(init5, round_keys, 8);

        r13 == reverse_bytes_nat64(hi64(buffer128_read(in0_b, 0, mem))); 
        r12 == reverse_bytes_nat64(lo64(buffer128_read(in0_b, 0, mem))); 
        rndkey == index(round_keys, 9);
{
    Load128_buffer(T1, key, 0x80-0x80, Secret, keys_b, 8); // # borrow $T1 for $rndkey

    VAESNI_enc(inout0, inout0, T1);
    Load128_buffer(rndkey, key, 0x90-0x80, Secret, keys_b, 9); 
    VAESNI_enc(inout1, inout1, T1);
    VAESNI_enc(inout2, inout2, T1);
    VAESNI_enc(inout3, inout3, T1);

    LoadBe64_buffer128(r13, in0, 0*16+8, Secret, true,  in0_b, 0);
    VAESNI_enc(inout4, inout4, T1);
    LoadBe64_buffer128(r12, in0, 0*16,   Secret, false, in0_b, 0);

    VAESNI_enc(inout5, inout5, T1);

    reveal rounds;
    commute_sub_bytes_shift_rows_forall();
}

procedure {:quick} loop6x_round9(
    inline alg:algorithm,  // OpenSSL includes the number of rounds (nr) as a dynamic parameter (stored with the key).  Saves code space but adds extra instructions to the fast path.  Maybe branch predictor is good enough for it not to matter
    ghost in_b:buffer128,
    ghost stack_b:buffer128,

    ghost key_words:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,

    ghost init0:quad32,
    ghost init1:quad32,
    ghost init2:quad32,
    ghost init3:quad32,
    ghost init4:quad32,
    ghost init5:quad32
    )
    lets
//      outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        inp @= rdi; key @= rcx; 
        Ii @= xmm0; T1 @= xmm1; T2 @= xmm2; Hkey @= xmm3;
        Z1 @= xmm5; Z2 @= xmm6; Z3 @= xmm7;
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;
        //in0 @= r14; 

    reads
        key; inp;
        mem; memTaint;

    modifies
        Ii; T1; T2; Hkey; Z1; Z2; Z3; inout0; inout1; inout2; inout3; inout4; inout5; rndkey;
        efl;

    requires
        // Valid ptrs and buffers
        validSrcAddrs128(mem, inp, in_b, 6, memTaint, Secret);

        // AES reqs
        aes_reqs(alg, key_words, round_keys, keys_b, key, mem, memTaint);

        inout0 == rounds_opaque(init0, round_keys, 8);
        inout1 == rounds_opaque(init1, round_keys, 8);
        inout2 == rounds_opaque(init2, round_keys, 8);
        inout3 == rounds_opaque(init3, round_keys, 8);
        inout4 == rounds_opaque(init4, round_keys, 8);
        inout5 == rounds_opaque(init5, round_keys, 8);

        rndkey == index(round_keys, 9);

    ensures
        // Semantics
        inout0 == rounds_opaque(init0, round_keys, 9);
        inout1 == rounds_opaque(init1, round_keys, 9);
        inout2 == rounds_opaque(init2, round_keys, 9);
        inout3 == rounds_opaque(init3, round_keys, 9);
        inout4 == rounds_opaque(init4, round_keys, 9);
        inout5 == rounds_opaque(init5, round_keys, 9);

        let rk := index(round_keys, 10);
        T2   == quad32_xor(rk, buffer128_read(in_b, 0, mem));
        Ii   == quad32_xor(rk, buffer128_read(in_b, 1, mem));
        Z1   == quad32_xor(rk, buffer128_read(in_b, 2, mem));
        Z2   == quad32_xor(rk, buffer128_read(in_b, 3, mem));
        Z3   == quad32_xor(rk, buffer128_read(in_b, 4, mem));
        Hkey == quad32_xor(rk, buffer128_read(in_b, 5, mem));
{
    Load128_buffer(T1, key, 0xa0-0x80, Secret, keys_b, 10); 

    // Would do more rounds here for AES-192 or 256

    VAESNI_enc(inout0, inout0, rndkey);
    VAESNI_enc(inout1, inout1, rndkey);
    VPxor_buffer(T2, T1, inp, 0x00, Secret, in_b, 0);
    VAESNI_enc(inout2, inout2, rndkey);
    VPxor_buffer(Ii, T1, inp, 0x10, Secret, in_b, 1);
    VAESNI_enc(inout3, inout3, rndkey);
    VPxor_buffer(Z1, T1, inp, 0x20, Secret, in_b, 2);
    VAESNI_enc(inout4, inout4, rndkey);
    VPxor_buffer(Z2, T1, inp, 0x30, Secret, in_b, 3);
    VAESNI_enc(inout5, inout5, rndkey);
    VPxor_buffer(Z3, T1, inp, 0x40, Secret, in_b, 4);
    VPxor_buffer(Hkey, T1, inp, 0x50, Secret, in_b, 5);

    reveal rounds;
    commute_sub_bytes_shift_rows_forall();
}

procedure {:quick} load_one_msb()
    lets constp @= r11; T2 @= xmm2; 
    modifies constp; T2; efl;
    ensures  T2 == Mkfour(0, 0, 0, 0x1000000);
{
    ZeroXmm(T2);
    assert two_to_nat32(Mktwo(0, 0x1000000)) == 0x100000000000000; // OBSERVE
    PinsrqImm(T2, 0x100000000000000, 1, constp);
    reveal insert_nat64;
}

#reset-options "--z3rlimit 30"
procedure {:quick} loop6x_final(
    inline alg:algorithm,  
    ghost iv_b:buffer128,
    ghost stack_b:buffer128,

    ghost key_words:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,

    ghost ctr_orig:quad32,

    ghost init0:quad32,
    ghost init1:quad32,
    ghost init2:quad32,
    ghost init3:quad32,
    ghost init4:quad32,
    ghost init5:quad32,
    ghost ctr0:quad32,
    ghost ctr1:quad32,
    ghost ctr2:quad32,
    ghost ctr3:quad32,
    ghost ctr4:quad32,
    ghost ctr5:quad32,
    ghost plain0:quad32,
    ghost plain1:quad32,
    ghost plain2:quad32,
    ghost plain3:quad32,
    ghost plain4:quad32,
    ghost plain5:quad32,
    ghost inb:quad32
    )
    lets
//      inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        inp @= rdi; outp @= rsi; key @= rcx; ivp @= r8;
        Ii @= xmm0; T1 @= xmm1; T2 @= xmm2; Hkey @= xmm3;
        Z1 @= xmm5; Z2 @= xmm6; Z3 @= xmm7;
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
        constp @= r11; 
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;

    reads
        key; rsp; ivp;
        memTaint;

    modifies
        inp; outp; constp; r12; r13; 
        Ii; T1; T2; Hkey; Z1; Z2; Z3; inout0; inout1; inout2; inout3; inout4; inout5; rndkey;
        mem; efl;

    requires
        // Valid ptrs and buffers
        validSrcAddrs128(mem, ivp, iv_b, 1, memTaint, Secret);
        validDstAddrs128(mem, rsp, stack_b, 8, memTaint, Secret);
        buffers_disjoint128(stack_b, keys_b);
         inp + 0x60 < pow2_64;
        outp + 0x60 < pow2_64;

        // AES reqs
        aes_reqs(alg, key_words, round_keys, keys_b, key, mem, memTaint);

        init0 == quad32_xor(ctr0, index(round_keys, 0));
        init1 == quad32_xor(ctr1, index(round_keys, 0));
        init2 == quad32_xor(ctr2, index(round_keys, 0));
        init3 == quad32_xor(ctr3, index(round_keys, 0));
        init4 == quad32_xor(ctr4, index(round_keys, 0));
        init5 == quad32_xor(ctr5, index(round_keys, 0));

        inout0 == rounds_opaque(init0, round_keys, 9);
        inout1 == rounds_opaque(init1, round_keys, 9);
        inout2 == rounds_opaque(init2, round_keys, 9);
        inout3 == rounds_opaque(init3, round_keys, 9);
        inout4 == rounds_opaque(init4, round_keys, 9);
        inout5 == rounds_opaque(init5, round_keys, 9);

        r13 == reverse_bytes_nat64(hi64(inb)); 
        r12 == reverse_bytes_nat64(lo64(inb)); 


        let rk := index(round_keys, 10);
        T2   == quad32_xor(rk, plain0);
        Ii   == quad32_xor(rk, plain1);
        Z1   == quad32_xor(rk, plain2);
        Z2   == quad32_xor(rk, plain3);
        Z3   == quad32_xor(rk, plain4);
        Hkey == quad32_xor(rk, plain5);

        buffer128_read(iv_b, 0, mem) == reverse_bytes_quad32(ctr_orig);

    ensures
        // Framing
        modifies_buffer_specific128(stack_b, old(mem), mem, 7, 8);

        // Semantics
        buffer128_read(stack_b, 7, mem) == reverse_bytes_quad32(inb);

        inout0 == quad32_xor(plain0, aes_encrypt_le(alg, key_words, ctr0));
        inout1 == quad32_xor(plain1, aes_encrypt_le(alg, key_words, ctr1));
        inout2 == quad32_xor(plain2, aes_encrypt_le(alg, key_words, ctr2));
        inout3 == quad32_xor(plain3, aes_encrypt_le(alg, key_words, ctr3));
        inout4 == quad32_xor(plain4, aes_encrypt_le(alg, key_words, ctr4));
        inout5 == quad32_xor(plain5, aes_encrypt_le(alg, key_words, ctr5));

        rndkey == index(round_keys, 0);

         inp == old( inp) + 0x60;
        outp == old(outp) + 0x60;

        T2 == Mkfour(0, 0, 0, 0x1000000);

        T1   == old(buffer128_read(iv_b, 0, mem));
        let ctr := ctr_orig.lo0 % 256;
        ctr + 6 < 256 ==> Ii   == reverse_bytes_quad32(inc32(ctr_orig, 1));
        ctr + 6 < 256 ==> Z1   == reverse_bytes_quad32(inc32(ctr_orig, 2));
        ctr + 6 < 256 ==> Z2   == reverse_bytes_quad32(inc32(ctr_orig, 3));
        ctr + 6 < 256 ==> Z3   == reverse_bytes_quad32(inc32(ctr_orig, 4));
        ctr + 6 < 256 ==> Hkey == reverse_bytes_quad32(inc32(ctr_orig, 5));
{
    lemma_quad32_xor_commutes_forall();
    Load128_buffer(T1, ivp, 0, Secret, iv_b, 0); // # load next counter value

    VAESNI_enc_last(inout0, inout0, T2);
    load_one_msb();                              // # borrow $T2, .Lone_msb
    VAESNI_enc_last(inout1, inout1, Ii);
    VPaddd(Ii, T1, T2);
    Store64_buffer128(rsp, r13, 7*16,   Secret, false, stack_b, 7);  // OpenSSL is further offset by 8 (to account for return addr?)
    AddLea64(inp, inp, 0x60);
    VAESNI_enc_last(inout2, inout2, Z1);
    VPaddd(Z1, Ii, T2);
    Store64_buffer128(rsp, r12, 7*16+8, Secret, true,  stack_b, 7);   // OpenSSL is further offset by 8 (to account for return addr?)
    AddLea64(outp, outp, 0x60);
    Load128_buffer(rndkey, key, 0x00-0x80, Secret, keys_b, 0); 

    VAESNI_enc_last(inout3, inout3, Z2);
    VPaddd(Z2, Z1, T2);
    VAESNI_enc_last(inout4, inout4, Z3);
    VPaddd(Z3, Z2, T2);
    VAESNI_enc_last(inout5, inout5, Hkey);
    VPaddd(Hkey, Z3, T2);

    finish_cipher_opt(alg, ctr0, plain0, init0, old(inout0), inout0, round_keys);
    finish_cipher_opt(alg, ctr1, plain1, init1, old(inout1), inout1, round_keys);
    finish_cipher_opt(alg, ctr2, plain2, init2, old(inout2), inout2, round_keys);
    finish_cipher_opt(alg, ctr3, plain3, init3, old(inout3), inout3, round_keys);
    finish_cipher_opt(alg, ctr4, plain4, init4, old(inout4), inout4, round_keys);
    finish_cipher_opt(alg, ctr5, plain5, init5, old(inout5), inout5, round_keys);
    finish_aes_encrypt_le(alg, ctr0, key_words);
    finish_aes_encrypt_le(alg, ctr1, key_words);
    finish_aes_encrypt_le(alg, ctr2, key_words);
    finish_aes_encrypt_le(alg, ctr3, key_words);
    finish_aes_encrypt_le(alg, ctr4, key_words);
    finish_aes_encrypt_le(alg, ctr5, key_words);

    lemma_reverse_bytes_quad32_64(inb, old(buffer128_read(stack_b, 7, mem)), buffer128_read(stack_b, 7, mem));

    lemma_incr_msb(ctr_orig, T1, Ii, 1);
    lemma_incr_msb(ctr_orig, T1, Z1, 2);
    lemma_incr_msb(ctr_orig, T1, Z2, 3);
    lemma_incr_msb(ctr_orig, T1, Z3, 4);
    lemma_incr_msb(ctr_orig, T1, Hkey, 5);
}

#reset-options ""
procedure {:quick} loop6x_save_output(
    ghost out_b:buffer128
    )
    lets
        outp @= rsi;  
        Ii @= xmm0; T1 @= xmm1; T2 @= xmm2; Hkey @= xmm3;
        Z1 @= xmm5; Z2 @= xmm6; Z3 @= xmm7;
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;

    reads
        outp;
        Ii; T1; T2; Hkey; Z1; Z2; Z3; rndkey; 
        memTaint;

    modifies
        inout0; inout1; inout2; inout3; inout4; inout5; 
        mem; efl;

    requires
        // Valid ptrs and buffers
        validDstAddrs128(mem, outp - 0x60, out_b, 6, memTaint, Secret);

    ensures
        modifies_buffer128(out_b, old(mem), mem);

        buffer128_read(out_b, 0, mem) == old(inout0);
        buffer128_read(out_b, 1, mem) == old(inout1);
        buffer128_read(out_b, 2, mem) == old(inout2);
        buffer128_read(out_b, 3, mem) == old(inout3);
        buffer128_read(out_b, 4, mem) == old(inout4);
        buffer128_read(out_b, 5, mem) == old(inout5);

        inout0 == quad32_xor(T1, rndkey);
        inout1 == Ii;
        inout2 == Z1;
        inout3 == Z2;
        inout4 == Z3;
        inout5 == Hkey;
        
{
    Store128_buffer(outp, inout0, 0-0x60, Secret, out_b, 0);
    VPxor(inout0, T1, rndkey);
    Store128_buffer(outp, inout1, 0-0x50, Secret, out_b, 1);
    Mov128(inout1, Ii);
    Store128_buffer(outp, inout2, 0-0x40, Secret, out_b, 2);
    Mov128(inout2, Z1);
    Store128_buffer(outp, inout3, 0-0x30, Secret, out_b, 3);
    Mov128(inout3, Z2);
    Store128_buffer(outp, inout4, 0-0x20, Secret, out_b, 4);
    Mov128(inout4, Z3);
    Store128_buffer(outp, inout5, 0-0x10, Secret, out_b, 5);
    Mov128(inout5, Hkey);
}


#reset-options "--z3rlimit 100"
procedure {:quick} loop6x(
    inline alg:algorithm,  
    ghost iv_b:buffer128,
    ghost in0_b:buffer128,
    ghost in_b:buffer128,
    ghost out_b:buffer128,
    ghost stack_b:buffer128,

    ghost key_words:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,

    ghost ctr_BE:quad32
    )
    lets
//      inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; 
        Ii @= xmm0; T1 @= xmm1; T2 @= xmm2; Hkey @= xmm3;
        Z1 @= xmm5; Z2 @= xmm6; Z3 @= xmm7;
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;
        counter @= rbx; constp @= r11; in0 @= r14; 

    reads
        key; ivp; rsp; in0;
        memTaint;

    modifies
        inp; outp; len; counter; constp; r12; r13; 
        Ii; T1; T2; Hkey; Z1; Z2; Z3; inout0; inout1; inout2; inout3; inout4; inout5; rndkey;
        mem; efl;

    requires
        len >= 6;
        T2 == Mkfour(0, 0, 0, 0x1000000);

        // Valid ptrs and buffers
        validDstAddrs128(mem, ivp, iv_b, 1, memTaint, Secret);
        validSrcAddrs128(mem, in0, in0_b, 6, memTaint, Secret);
        validSrcAddrs128(mem, inp, in_b, 6, memTaint, Secret);
        validDstAddrs128(mem, outp, out_b, 6, memTaint, Secret);
        validDstAddrs128(mem, rsp, stack_b, 8, memTaint, Secret);
        buffers_disjoint128(iv_b, keys_b);
        buffers_disjoint128(iv_b, stack_b);
        buffers_disjoint128(iv_b, in0_b);
        buffers_disjoint128(iv_b, in_b);
        buffers_disjoint128(stack_b, keys_b);
        buffers_disjoint128(stack_b, in0_b);
        buffers_disjoint128(stack_b, in_b);
        buffers_disjoint128(stack_b, out_b);
         inp + 0x60 < pow2_64;
        outp + 0x60 < pow2_64;

        // AES reqs
        aes_reqs(alg, key_words, round_keys, keys_b, key, mem, memTaint);
        rndkey == index(round_keys, 0);

        // Counter requirements
        /*
        // TODO: Clean this up
        inout5.hi3 + 0x1000000 < pow2_32;
        reverse_bytes_quad32(inc32(ctr_BE, 6)).hi3 + (5*0x1000000) < pow2_32;

        T1 == reverse_bytes_quad32(ctr_BE);
        */

        T2 == Mkfour(0, 0, 0, 0x1000000);
        T1 == reverse_bytes_quad32(inc32(ctr_BE, 0));
        counter == ctr_BE.lo0 % 256;

        inout0 == quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 0)), rndkey);   

        counter + 6 < 256 ==> inout1 == reverse_bytes_quad32(inc32(ctr_BE, 1));
        counter + 6 < 256 ==> inout2 == reverse_bytes_quad32(inc32(ctr_BE, 2));
        counter + 6 < 256 ==> inout3 == reverse_bytes_quad32(inc32(ctr_BE, 3));
        counter + 6 < 256 ==> inout4 == reverse_bytes_quad32(inc32(ctr_BE, 4));
        counter + 6 < 256 ==> inout5 == reverse_bytes_quad32(inc32(ctr_BE, 5));

    ensures
        len == old(len) - 6;
        T2 == Mkfour(0, 0, 0, 0x1000000);

         inp == old( inp) + 0x60;
        outp == old(outp) + 0x60;

        rndkey == index(round_keys, 0);

        T1   == reverse_bytes_quad32(inc32(ctr_BE, 6));
        counter + 6 < 256 ==> Ii   == reverse_bytes_quad32(inc32(ctr_BE, 7));
        counter + 6 < 256 ==> Z1   == reverse_bytes_quad32(inc32(ctr_BE, 8));
        counter + 6 < 256 ==> Z2   == reverse_bytes_quad32(inc32(ctr_BE, 9));
        counter + 6 < 256 ==> Z3   == reverse_bytes_quad32(inc32(ctr_BE,10));
        counter + 6 < 256 ==> Hkey == reverse_bytes_quad32(inc32(ctr_BE,11));

        len == 0 ==> inout0 == quad32_xor(old(buffer128_read(in_b, 0, mem)), aes_encrypt_BE(alg, key_words, inc32(ctr_BE, 0)));
        len == 0 ==> inout1 == quad32_xor(old(buffer128_read(in_b, 1, mem)), aes_encrypt_BE(alg, key_words, inc32(ctr_BE, 1)));
        len == 0 ==> inout2 == quad32_xor(old(buffer128_read(in_b, 2, mem)), aes_encrypt_BE(alg, key_words, inc32(ctr_BE, 2)));
        len == 0 ==> inout3 == quad32_xor(old(buffer128_read(in_b, 3, mem)), aes_encrypt_BE(alg, key_words, inc32(ctr_BE, 3)));
        len == 0 ==> inout4 == quad32_xor(old(buffer128_read(in_b, 4, mem)), aes_encrypt_BE(alg, key_words, inc32(ctr_BE, 4)));
        len == 0 ==> inout5 == quad32_xor(old(buffer128_read(in_b, 5, mem)), aes_encrypt_BE(alg, key_words, inc32(ctr_BE, 5)));

        len > 0 ==> inout0 == quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 6)), rndkey);
        len > 0 ==> inout1 == Ii;
        len > 0 ==> inout2 == Z1;
        len > 0 ==> inout3 == Z2;
        len > 0 ==> inout4 == Z3;
        len > 0 ==> inout5 == Hkey;

        buffer128_read(stack_b, 2, mem) == old(reverse_bytes_quad32(buffer128_read(in0_b, 5, mem)));
        buffer128_read(stack_b, 3, mem) == old(reverse_bytes_quad32(buffer128_read(in0_b, 4, mem)));
        buffer128_read(stack_b, 4, mem) == old(reverse_bytes_quad32(buffer128_read(in0_b, 3, mem)));
        buffer128_read(stack_b, 5, mem) == old(reverse_bytes_quad32(buffer128_read(in0_b, 2, mem)));
        buffer128_read(stack_b, 6, mem) == old(reverse_bytes_quad32(buffer128_read(in0_b, 1, mem)));
        buffer128_read(stack_b, 7, mem) == old(reverse_bytes_quad32(buffer128_read(in0_b, 0, mem)));
{
    ghost var init0 := inout0;
    ghost var init1 := quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 1)), rndkey);
    ghost var init2 := quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 2)), rndkey);
    ghost var init3 := quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 3)), rndkey);
    ghost var init4 := quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 4)), rndkey);
    ghost var init5 := quad32_xor(reverse_bytes_quad32(inc32(ctr_BE, 5)), rndkey);

    loop6x_preamble(alg, iv_b, key_words, round_keys, keys_b, ctr_BE);
    loop6x_step(alg, 1, 5, 2, in0_b, stack_b, key_words, round_keys, keys_b, 
                init0, init1, init2, init3, init4, init5);
    loop6x_plain(alg, 2, key_words, round_keys, keys_b, 
                 init0, init1, init2, init3, init4, init5);
    loop6x_step(alg, 3, 4, 3, in0_b, stack_b, key_words, round_keys, keys_b, 
                init0, init1, init2, init3, init4, init5);
    loop6x_step(alg, 4, 3, 4, in0_b, stack_b, key_words, round_keys, keys_b, 
                init0, init1, init2, init3, init4, init5);
    loop6x_step(alg, 5, 2, 5, in0_b, stack_b, key_words, round_keys, keys_b, 
                init0, init1, init2, init3, init4, init5);
    loop6x_step(alg, 6, 1, 6, in0_b, stack_b, key_words, round_keys, keys_b, 
                init0, init1, init2, init3, init4, init5);
    loop6x_round8(alg, in0_b, stack_b, key_words, round_keys, keys_b, 
                  init0, init1, init2, init3, init4, init5);
    loop6x_round9(alg, in_b, stack_b, key_words, round_keys, keys_b, 
                  init0, init1, init2, init3, init4, init5);
    loop6x_final(alg, iv_b, stack_b, key_words, round_keys, keys_b, 
                 reverse_bytes_quad32(buffer128_read(iv_b, 0, mem)), init0, init1, init2, init3, init4, init5,
                 reverse_bytes_quad32(inc32(ctr_BE, 0)), 
                 reverse_bytes_quad32(inc32(ctr_BE, 1)), 
                 reverse_bytes_quad32(inc32(ctr_BE, 2)), 
                 reverse_bytes_quad32(inc32(ctr_BE, 3)), 
                 reverse_bytes_quad32(inc32(ctr_BE, 4)), 
                 reverse_bytes_quad32(inc32(ctr_BE, 5)), 
                 buffer128_read(in_b, 0, mem),
                 buffer128_read(in_b, 1, mem),
                 buffer128_read(in_b, 2, mem),
                 buffer128_read(in_b, 3, mem),
                 buffer128_read(in_b, 4, mem),
                 buffer128_read(in_b, 5, mem),
                 buffer128_read(in0_b, 0, mem));

    Sub64(len, 6);

    if (len > 0) {
        loop6x_save_output(out_b);
    }
}
