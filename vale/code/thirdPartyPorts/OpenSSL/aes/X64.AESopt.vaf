include "../../../arch/x64/X64.Vale.InsBasic.vaf"
include "../../../arch/x64/X64.Vale.InsMem.vaf"
include "../../../arch/x64/X64.Vale.InsVector.vaf"
include "../../../arch/x64/X64.Vale.InsAes.vaf"
include{:fstar}{:open} "Prop_s"
include{:fstar}{:open} "Opaque_s"
include{:fstar}{:open} "Words_s"
include{:fstar}{:open} "Types_s"
include{:/*TODO*/fstar}{:open} "FStar.Seq.Base"
include{:fstar}{:open} "AES_s"
include{:fstar}{:open} "X64.Machine_s"
include{:fstar}{:open} "X64.Memory"
include{:fstar}{:open} "X64.Vale.State"
include{:fstar}{:open} "X64.Vale.Decls"
include{:fstar}{:open} "X64.Vale.QuickCode"
include{:fstar}{:open} "X64.Vale.QuickCodes"
include{:fstar}{:open} "Arch.Types"
include{:fstar}{:open} "AES_helpers"
include{:fstar}{:open} "X64.Poly1305.Math"
include{:fstar}{:open} "GCM_helpers"
include{:fstar}{:open} "Workarounds"
include{:fstar}{:open} "GCTR_s"
include{:fstar}{:open} "GCTR"
include{:fstar}{:open} "Arch.TypesNative"
include{:fstar}{:open} "X64.CPU_Features_s"

module X64.AESopt

#verbatim{:interface}{:implementation}
open Prop_s
open Opaque_s
open Words_s
open Types_s
open FStar.Seq
open AES_s
open X64.Machine_s
open X64.Memory
open X64.Vale.State
open X64.Vale.Decls
open X64.Vale.InsBasic
open X64.Vale.InsMem
open X64.Vale.InsVector
open X64.Vale.InsAes
open X64.Vale.QuickCode
open X64.Vale.QuickCodes
open Arch.Types
open AES_helpers
open X64.Poly1305.Math    // For lemma_poly_bits64()
open GCM_helpers
open Workarounds
open GCTR_s
open GCTR
open Arch.TypesNative
open X64.CPU_Features_s
#endverbatim

#verbatim{:interface}
let aes_reqs
  (alg:algorithm) (key:seq nat32) (round_keys:seq quad32) (keys_b:buffer128)
  (key_ptr:nat64) (mem:memory) (memTaint:memtaint) : prop0
  =
  aesni_enabled /\
  alg = AES_128 /\
  //(alg = AES_128 || alg = AES_256) /\
  is_aes_key_LE alg key /\
  length(round_keys) == nr(alg) + 1 /\
  round_keys == key_to_round_keys_LE alg key /\

  //validSrcAddrsOffset128 mem key_ptr keys_b 8 (nr alg + 1) memTaint Secret /\
  // Can't use the standard Offset, since that makes the size too large and conflicts
  // with the spec below that says the entire keys_b is exactly round_keys
  buffer_readable mem keys_b /\
  (nr alg + 1) <= buffer_length keys_b /\
  buffer_addr keys_b mem + 16 `op_Multiply` 8 == key_ptr /\
  valid_taint_buf128 keys_b mem memTaint Secret /\

  buffer128_as_seq mem keys_b == round_keys
#endverbatim
function aes_reqs(alg:algorithm, key:seq(nat32), round_keys:seq(quad32), keys_b:buffer128,
    key_ptr:nat64, mem:memory, memTaint:memtaint) : prop extern;

ghost procedure finish_aes_encrypt_le(ghost alg:algorithm, ghost input_LE:quad32, ghost key:seq(nat32))
    requires
        is_aes_key_LE(alg, key);
    ensures
        aes_encrypt_le(alg, key, input_LE) == cipher_opaque(alg, input_LE, key_to_round_keys_LE(alg, key));
{
    reveal aes_encrypt_LE_def;
    reveal cipher;
}

procedure {:quick} {:verify true} loop6x_preamble(
    inline alg:algorithm,  // OpenSSL includes the number of rounds (nr) as a dynamic parameter (stored with the key).  Saves code space but adds extra instructions to the fast path.  Maybe branch predictor is good enough for it not to matter
    ghost iv_b:buffer128,

    ghost key_words:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128

    )
    lets
//      inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        key @= rcx; ivp @= r8; 
        T1 @= xmm1; T2 @= xmm2; 
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;

    reads
        key; ivp;
        memTaint;

    modifies
        T1; T2; inout0; inout1; inout2; inout3; inout4; inout5; rndkey;
        mem; efl;

    requires
        // Valid ptrs and buffers
        validDstAddrs128(mem, ivp, iv_b, 1, memTaint, Secret);

        // AES reqs
        aes_reqs(alg, key_words, round_keys, keys_b, key, mem, memTaint);
        rndkey == index(round_keys, 0);

    ensures
//        inout0 == rounds_opaque(old(inout0), round_keys, 1);
//        inout1 == rounds_opaque(old(quad32_xor(inout1, rndkey)), round_keys, 1);
//        inout2 == rounds_opaque(old(quad32_xor(inout2, rndkey)), round_keys, 1);
//        inout3 == rounds_opaque(old(quad32_xor(inout3, rndkey)), round_keys, 1);
//        inout4 == rounds_opaque(old(quad32_xor(inout4, rndkey)), round_keys, 1);
//        inout5 == rounds_opaque(old(quad32_xor(inout5, rndkey)), round_keys, 1);
//
//        buffer128_read(iv_b, 0, mem) == old(add_wrap_quad32(T2, inout5));
{
    init_rounds_opaque(inout0, round_keys);

    VPaddd(T1, T2, inout5); // OpenSSL uses VPaddb
    VPxor(inout1, inout1, rndkey); init_rounds_opaque(inout1, round_keys);
    VPxor(inout2, inout2, rndkey); init_rounds_opaque(inout2, round_keys);

    Store128_buffer(ivp, T1, 0, Secret, iv_b, 0);   // # save next counter value
    VPxor(inout3, inout3, rndkey); init_rounds_opaque(inout3, round_keys);
    Load128_buffer(T2, key, 0x10-0x80, Secret, keys_b, 1); // # borrow $T2 for $rndkey

    VAESNI_enc(inout0, inout0, T2);
    VPxor(inout4, inout4, rndkey); init_rounds_opaque(inout4, round_keys);
    VAESNI_enc(inout1, inout1, T2);
    VPxor(inout5, inout5, rndkey); init_rounds_opaque(inout5, round_keys);
    VAESNI_enc(inout2, inout2, T2);
    VAESNI_enc(inout3, inout3, T2);
    VAESNI_enc(inout4, inout4, T2);
    Load128_buffer(rndkey, key, 0x20-0x80, Secret, keys_b, 2);
    VAESNI_enc(inout5, inout5, T2);

    reveal rounds;
    commute_sub_bytes_shift_rows_forall();
}
/*
procedure {:quick} loop6x_plain(
    inline alg:algorithm,  // OpenSSL includes the number of rounds (nr) as a dynamic parameter (stored with the key).  Saves code space but adds extra instructions to the fast path.  Maybe branch predictor is good enough for it not to matter
    ghost key_words:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,

    ghost init0:quad32,
    ghost init1:quad32,
    ghost init2:quad32,
    ghost init3:quad32,
    ghost init4:quad32,
    ghost init5:quad32
    )
    lets
//      inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        key @= rcx; 
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;

    reads
        key; 
        memTaint;

    modifies
        inout0; inout1; inout2; inout3; inout4; inout5; rndkey;
        mem; efl;

    requires
        // AES reqs
        aes_reqs(alg, key_words, round_keys, keys_b, key, mem, memTaint);

        inout0 == rounds_opaque(init0, round_keys, 3);
        inout1 == rounds_opaque(init1, round_keys, 3);
        inout2 == rounds_opaque(init2, round_keys, 3);
        inout3 == rounds_opaque(init3, round_keys, 3);
        inout4 == rounds_opaque(init4, round_keys, 3);
        inout5 == rounds_opaque(init5, round_keys, 3);

    ensures
        inout0 == rounds_opaque(init0, round_keys, 4);
        inout1 == rounds_opaque(init1, round_keys, 4);
        inout2 == rounds_opaque(init2, round_keys, 4);
        inout3 == rounds_opaque(init3, round_keys, 4);
        inout4 == rounds_opaque(init4, round_keys, 4);
        inout5 == rounds_opaque(init5, round_keys, 4);

        // TODO:
//        buffer128_read(stack_b, 3, mem) == reverse_bytes_nat64(old(buffer64_read(in_b, 9, mem)))
//                                           reverse_bytes_nat64(old(buffer64_read(in_b, 8, mem)))
{
    Load128_buffer(rndkey, key, 0x40-0x80, Secret, keys_b, 4);

    VAESNI_enc(inout0, inout0, rndkey);
    VAESNI_enc(inout1, inout1, rndkey);
    VAESNI_enc(inout2, inout2, rndkey);
    VAESNI_enc(inout3, inout3, rndkey);
    VAESNI_enc(inout4, inout4, rndkey);
    VAESNI_enc(inout5, inout5, rndkey);
}

procedure {:quick} loop6x_step(
    inline alg:algorithm,  // OpenSSL includes the number of rounds (nr) as a dynamic parameter (stored with the key).  Saves code space but adds extra instructions to the fast path.  Maybe branch predictor is good enough for it not to matter
    ghost in_b:buffer64,
    ghost stack_b:buffer128,

    ghost key_words:seq(nat32),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128,

    ghost init0:quad32,
    ghost init1:quad32,
    ghost init2:quad32,
    ghost init3:quad32,
    ghost init4:quad32,
    ghost init5:quad32
    )
    lets
//      inp @= rdi; outp @= rsi; len @= rdx; key @= rcx; ivp @= r8; Xip @= r9;
        key @= rcx; 
        inout0 @= xmm9; inout1 @= xmm10; inout2 @= xmm11; inout3 @= xmm12;
        inout4 @= xmm13; inout5 @= xmm14; rndkey @= xmm15;
//      counter @= rbx; rounds @= rbp; ret @= r10; constp @= r11; in0 @= r14; end0 @= r15;
        in0 @= r14; 

    reads
        key; rsp; in0;
        memTaint;

    modifies
        r12; r13; 
        inout0; inout1; inout2; inout3; inout4; inout5; rndkey;
        mem; efl;

    requires
        // Valid ptrs and buffers
        validSrcAddrs64(mem, in0, in_b, 10, memTaint, Secret);
        validDstAddrs128(mem, rsp, stack_b, 4, memTaint, Secret);

        // AES reqs
        aes_reqs(alg, key_words, round_keys, keys_b, key, mem, memTaint);

        inout0 == rounds_opaque(init0, round_keys, 3);
        inout1 == rounds_opaque(init1, round_keys, 3);
        inout2 == rounds_opaque(init2, round_keys, 3);
        inout3 == rounds_opaque(init3, round_keys, 3);
        inout4 == rounds_opaque(init4, round_keys, 3);
        inout5 == rounds_opaque(init5, round_keys, 3);

    ensures
        inout0 == rounds_opaque(init0, round_keys, 4);
        inout1 == rounds_opaque(init1, round_keys, 4);
        inout2 == rounds_opaque(init2, round_keys, 4);
        inout3 == rounds_opaque(init3, round_keys, 4);
        inout4 == rounds_opaque(init4, round_keys, 4);
        inout5 == rounds_opaque(init5, round_keys, 4);

        // TODO:
//        buffer128_read(stack_b, 3, mem) == reverse_bytes_nat64(old(buffer64_read(in_b, 9, mem)))
//                                           reverse_bytes_nat64(old(buffer64_read(in_b, 8, mem)))
{
    Load128_buffer(rndkey, key, 0x40-0x80, Secret, keys_b, 4);

    VAESNI_enc(inout0, inout0, rndkey);
    VAESNI_enc(inout1, inout1, rndkey);

    LoadBe64_buffer(r13, in0, 0x48, Secret, in_b, 9);

    VAESNI_enc(inout2, inout2, rndkey);

    LoadBe64_buffer(r12, in0, 0x40, Secret, in_b, 8);

    VAESNI_enc(inout3, inout3, rndkey);

    Store64_128_buffer(rsp, r13, 0x30, Secret, stack_b, 3, false);  // OpenSSL uses 0x30+8

    VAESNI_enc(inout4, inout4, rndkey);

    Store64_128_buffer(rsp, r12, 0x38, Secret, stack_b, 3, true);   // OpenSSL uses 0x38+8

    VAESNI_enc(inout5, inout5, rndkey);

}
*/
