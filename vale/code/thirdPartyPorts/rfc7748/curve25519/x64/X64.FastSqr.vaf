include "../../../../arch/x64/X64.Vale.InsBasic.vaf"
include "../../../../arch/x64/X64.Vale.InsMem.vaf"
include{:fstar}{:open} "FastMul_helpers"
include{:fstar}{:open} "FastMul_defs"
include{:fstar}{:open} "X64.CPU_Features_s"

module X64.FastSqr

#reset-options "--z3rlimit 30"

#verbatim{:interface}
open Types_s
open Arch.Types
open X64.Machine_s
open X64.Memory
open X64.Vale.State
open X64.Vale.Decls
open X64.Vale.InsBasic
open X64.Vale.InsMem
open X64.Vale.QuickCode
open X64.Vale.QuickCodes
open FastMul_defs
open X64.CPU_Features_s
#endverbatim

#verbatim{:implementation}
open Types_s
open Arch.Types
open X64.Machine_s
open X64.Memory
open X64.Vale.State
open X64.Vale.Decls
open X64.Vale.InsBasic
open X64.Vale.InsMem
open X64.Vale.QuickCode
open X64.Vale.QuickCodes
open FStar.Tactics
open FastMul_defs
open FastMul_helpers
open X64.CPU_Features_s
#endverbatim

type tactic:Type(0) extern;
const int_canon:tactic extern;
ghost procedure assert_by_tactic(ghost p:prop, ghost t:tactic) extern;

/*
    "movq   (%1), %%rdx        ;" /* A[0]      */
    "mulx  8(%1),  %%r8, %%r14 ;" /* A[1]*A[0] */  "xorl %%r15d, %%r15d;"
    "mulx 16(%1),  %%r9, %%r10 ;" /* A[2]*A[0] */  "adcx %%r14,  %%r9 ;"
    "mulx 24(%1), %%rax, %%rcx ;" /* A[3]*A[0] */  "adcx %%rax, %%r10 ;"
    "movq 24(%1), %%rdx        ;" /* A[3]      */
    "mulx  8(%1), %%r11, %%r12 ;" /* A[1]*A[3] */  "adcx %%rcx, %%r11 ;"
    "mulx 16(%1), %%rax, %%r13 ;" /* A[2]*A[3] */  "adcx %%rax, %%r12 ;"
    "movq  8(%1), %%rdx        ;" /* A[1]      */  "adcx %%r15, %%r13 ;"
    "mulx 16(%1), %%rax, %%rcx ;" /* A[2]*A[1] */  "movq    $0, %%r14 ;"
    /*******************************************/  "adcx %%r15, %%r14 ;"

    "xorl %%r15d, %%r15d;"
    "adox %%rax, %%r10 ;"  "adcx  %%r8,  %%r8 ;"
    "adox %%rcx, %%r11 ;"  "adcx  %%r9,  %%r9 ;"
    "adox %%r15, %%r12 ;"  "adcx %%r10, %%r10 ;"
    "adox %%r15, %%r13 ;"  "adcx %%r11, %%r11 ;"
    "adox %%r15, %%r14 ;"  "adcx %%r12, %%r12 ;"
                           "adcx %%r13, %%r13 ;"
                           "adcx %%r14, %%r14 ;"

    "movq   (%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* A[0]^2 */
    /********************/  "movq %%rax,  0(%0) ;"
    "addq %%rcx,  %%r8 ;"   "movq  %%r8,  8(%0) ;"
    "movq  8(%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* A[1]^2 */
    "adcq %%rax,  %%r9 ;"   "movq  %%r9, 16(%0) ;"
    "adcq %%rcx, %%r10 ;"   "movq %%r10, 24(%0) ;"
    "movq 16(%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* A[2]^2 */
    "adcq %%rax, %%r11 ;"   "movq %%r11, 32(%0) ;"
    "adcq %%rcx, %%r12 ;"   "movq %%r12, 40(%0) ;"
    "movq 24(%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* A[3]^2 */
    "adcq %%rax, %%r13 ;"   "movq %%r13, 48(%0) ;"
    "adcq %%rcx, %%r14 ;"   "movq %%r14, 56(%0) ;"


    "movq 32(%1), %%rdx        ;" /* B[0]      */
    "mulx 40(%1),  %%r8, %%r14 ;" /* B[1]*B[0] */  "xorl %%r15d, %%r15d;"
    "mulx 48(%1),  %%r9, %%r10 ;" /* B[2]*B[0] */  "adcx %%r14,  %%r9 ;"
    "mulx 56(%1), %%rax, %%rcx ;" /* B[3]*B[0] */  "adcx %%rax, %%r10 ;"
    "movq 56(%1), %%rdx        ;" /* B[3]      */
    "mulx 40(%1), %%r11, %%r12 ;" /* B[1]*B[3] */  "adcx %%rcx, %%r11 ;"
    "mulx 48(%1), %%rax, %%r13 ;" /* B[2]*B[3] */  "adcx %%rax, %%r12 ;"
    "movq 40(%1), %%rdx        ;" /* B[1]      */  "adcx %%r15, %%r13 ;"
    "mulx 48(%1), %%rax, %%rcx ;" /* B[2]*B[1] */  "movq    $0, %%r14 ;"
    /*******************************************/  "adcx %%r15, %%r14 ;"

    "xorl %%r15d, %%r15d;"
    "adox %%rax, %%r10 ;"  "adcx  %%r8,  %%r8 ;"
    "adox %%rcx, %%r11 ;"  "adcx  %%r9,  %%r9 ;"
    "adox %%r15, %%r12 ;"  "adcx %%r10, %%r10 ;"
    "adox %%r15, %%r13 ;"  "adcx %%r11, %%r11 ;"
    "adox %%r15, %%r14 ;"  "adcx %%r12, %%r12 ;"
                           "adcx %%r13, %%r13 ;"
                           "adcx %%r14, %%r14 ;"

    "movq 32(%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* B[0]^2 */
    /********************/  "movq %%rax,  64(%0) ;"
    "addq %%rcx,  %%r8 ;"   "movq  %%r8,  72(%0) ;"
    "movq 40(%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* B[1]^2 */
    "adcq %%rax,  %%r9 ;"   "movq  %%r9,  80(%0) ;"
    "adcq %%rcx, %%r10 ;"   "movq %%r10,  88(%0) ;"
    "movq 48(%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* B[2]^2 */
    "adcq %%rax, %%r11 ;"   "movq %%r11,  96(%0) ;"
    "adcq %%rcx, %%r12 ;"   "movq %%r12, 104(%0) ;"
    "movq 56(%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* B[3]^2 */
    "adcq %%rax, %%r13 ;"   "movq %%r13, 112(%0) ;"
    "adcq %%rcx, %%r14 ;"   "movq %%r14, 120(%0) ;"

*/

#reset-options "--z3rlimit 300"
procedure{:quick} {:verify true} fast_sqr_part1(
    ghost inA_b:buffer64)
    lets
        inA_ptr @= rsi;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        a := pow2_four(a0, a1, a2, a3);
    reads
        inA_ptr; mem; memTaint;

    modifies
        rax; rcx; rdx; r8; r9; r10; r11; r12; r13; r14; r15;
        efl;

    requires
        adx_enabled && bmi2_enabled;

        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);

    ensures
        pow2_six(r8, r9, r10, r11, r12, r13) ==
        pow2_five(mul_nats(a0,a1), mul_nats(a0,a2), mul_nats(a0,a3), mul_nats(a1,a3), mul_nats(a2,a3));

        pow2_64 * rcx + rax == a1 * a2;
{
    xor_lemmas();

//    "movq   (%1), %%rdx        ;" /* A[0]      */
//    "mulx  8(%1),  %%r8, %%r14 ;" /* A[1]*A[0] */  "xorl %%r15d, %%r15d;"
//    "mulx 16(%1),  %%r9, %%r10 ;" /* A[2]*A[0] */  "adcx %%r14,  %%r9 ;"
//    "mulx 24(%1), %%rax, %%rcx ;" /* A[3]*A[0] */  "adcx %%rax, %%r10 ;"
//    "movq 24(%1), %%rdx        ;" /* A[3]      */
//    "mulx  8(%1), %%r11, %%r12 ;" /* A[1]*A[3] */  "adcx %%rcx, %%r11 ;"
//    "mulx 16(%1), %%rax, %%r13 ;" /* A[2]*A[3] */  "adcx %%rax, %%r12 ;"
//    "movq  8(%1), %%rdx        ;" /* A[1]      */  "adcx %%r15, %%r13 ;"
//    "mulx 16(%1), %%rax, %%rcx ;" /* A[2]*A[1] */  "movq    $0, %%r14 ;"
//    /*******************************************/  "adcx %%r15, %%r14 ;"

    Load64_buffer(rdx, inA_ptr,  0, Secret, inA_b, 0);     /* A[0] */
    lemma_load_mem64(inA_b, 1, mem);
    /* The Xor64 clears the flags used for carry bits; NOTE: Original code uses xorl with r15d, maybe produces smaller code? */
    Mulx64(r14, r8, Mem(inA_ptr,  8, inA_b, 1, Secret));  /* A[0]*A[1] */ lemma_prod_bounds(r14,  r8, a0, a1);  Xor64(r15, r15);  

    lemma_load_mem64(inA_b, 2, mem);
    Mulx64(r10, r9, Mem(inA_ptr, 16, inA_b, 2, Secret));  /* A[0]*A[2] */ lemma_prod_bounds(r10,  r9, a0, a2);  Adcx64Wrap( r9, r14);    
    
    lemma_load_mem64(inA_b, 3, mem);
    Mulx64(rcx,rax, Mem(inA_ptr, 24, inA_b, 3, Secret));  /* A[0]*A[3] */ lemma_prod_bounds(rcx, rax, a0, a3);  Adcx64Wrap(r10, rax);    

    Load64_buffer(rdx, inA_ptr,  24, Secret, inA_b, 3);     /* A[3] */

    lemma_load_mem64(inA_b, 1, mem);
    Mulx64(r12,r11, Mem(inA_ptr,  8, inA_b, 1, Secret));  /* A[3]*A[1] */ lemma_prod_bounds(r12, r11, a3, a1);  Adcx64Wrap(r11, rcx);

    lemma_load_mem64(inA_b, 2, mem);
    Mulx64(r13,rax, Mem(inA_ptr, 16, inA_b, 2, Secret));  /* A[3]*A[2] */ lemma_prod_bounds(r13, rax, a3, a2);  Adcx64Wrap(r12, rax);    

    Load64_buffer(rdx, inA_ptr,   8, Secret, inA_b, 1);     /* A[1] */                                          Adcx64Wrap(r13, r15);  // r15 = 0, r13 < pow2_64 - 1, so this wraps the carry into r13

//    assert !cf(efl);

    lemma_load_mem64(inA_b, 2, mem);
    Mulx64(rcx,rax, Mem(inA_ptr, 16, inA_b, 2, Secret));  /* A[1]*A[2] */ lemma_prod_bounds(rcx, rax, a1, a2);  Mov64(r14, 0);

//    assert r14 == 0;
//    assert r15 == 0;
//    Adcx64Wrap(r14, r15);     // <-- This appears to be redundant as cf, r14, and r15 are all provably 0 at this point

}

procedure{:quick} fast_sqr_part2(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        a := pow2_four(a0, a1, a2, a3);
    reads
        dst_ptr; inA_ptr; memTaint;

    modifies
        rax; rcx; rdx; r8; r9; r10; r11; r12; r13; r14; r15;
        mem; efl;

    requires
        adx_enabled && bmi2_enabled;
        buffers_disjoint(dst_b, inA_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);

    ensures
//        let d0 := buffer64_read(dst_b, 0, mem);
//        let d1 := buffer64_read(dst_b, 1, mem);
//        let a0b := d0 + pow2_64 * d1 + pow2_128 * r12 + pow2_192 * r14 + pow2_256 * rax; 
//        a0b == a0 * b;
//
//        validSrcAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
//        modifies_buffer(dst_b, old(mem), mem);
{
    xor_lemmas();

//    "xorl %%r15d, %%r15d;"
//    "adox %%rax, %%r10 ;"  "adcx  %%r8,  %%r8 ;"
//    "adox %%rcx, %%r11 ;"  "adcx  %%r9,  %%r9 ;"
//    "adox %%r15, %%r12 ;"  "adcx %%r10, %%r10 ;"
//    "adox %%r15, %%r13 ;"  "adcx %%r11, %%r11 ;"
//    "adox %%r15, %%r14 ;"  "adcx %%r12, %%r12 ;"
//                           "adcx %%r13, %%r13 ;"
//                           "adcx %%r14, %%r14 ;"

    Xor64(r15, r15);
    Adox64Wrap(r10, rax);     Adcx64Wrap(r8, r8);
    Adox64Wrap(r11, rcx);     Adcx64Wrap(r9, r9);
    Adox64Wrap(r12, r15);     Adcx64Wrap(r10, r10);
    Adox64Wrap(r13, r15);     Adcx64Wrap(r11, r11);
    Adox64Wrap(r14, r15);     Adcx64Wrap(r12, r12);
                              Adcx64Wrap(r13, r13);
                              Adcx64Wrap(r14, r14);
}

procedure{:quick}fast_sqr_part3(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        a := pow2_four(a0, a1, a2, a3);
    reads
        dst_ptr; inA_ptr; memTaint;

    modifies
        rax; rcx; rdx; r8; r9; r10; r11; r12; r13; r14; r15;
        mem; efl;

    requires
        adx_enabled && bmi2_enabled;
        buffers_disjoint(dst_b, inA_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);

    ensures
//        let d0 := buffer64_read(dst_b, 0, mem);
//        let d1 := buffer64_read(dst_b, 1, mem);
//        let a0b := d0 + pow2_64 * d1 + pow2_128 * r12 + pow2_192 * r14 + pow2_256 * rax; 
//        a0b == a0 * b;
//
//        validSrcAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
//        modifies_buffer(dst_b, old(mem), mem);
{
    xor_lemmas();

//    "movq   (%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* A[0]^2 */
//    /********************/  "movq %%rax,  0(%0) ;"
//    "addq %%rcx,  %%r8 ;"   "movq  %%r8,  8(%0) ;"
//    "movq  8(%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* A[1]^2 */
//    "adcq %%rax,  %%r9 ;"   "movq  %%r9, 16(%0) ;"
//    "adcq %%rcx, %%r10 ;"   "movq %%r10, 24(%0) ;"
//    "movq 16(%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* A[2]^2 */
//    "adcq %%rax, %%r11 ;"   "movq %%r11, 32(%0) ;"
//    "adcq %%rcx, %%r12 ;"   "movq %%r12, 40(%0) ;"
//    "movq 24(%1), %%rdx ;"  "mulx %%rdx, %%rax, %%rcx ;" /* A[3]^2 */
//    "adcq %%rax, %%r13 ;"   "movq %%r13, 48(%0) ;"
//    "adcq %%rcx, %%r14 ;"   "movq %%r14, 56(%0) ;"

    Load64_buffer(rdx, inA_ptr,  0, Secret, inA_b, 0);   Mulx64(rcx, rax, rdx);  /* A[0]^2 */
    /********************/                               Store64_buffer(dst_ptr, rax,  0, Secret, dst_b, 0);
    Add64Wrap(r8, rcx);                                  Store64_buffer(dst_ptr,  r8,  8, Secret, dst_b, 1);
    Load64_buffer(rdx, inA_ptr,  8, Secret, inA_b, 1);   Mulx64(rcx, rax, rdx);  /* A[1]^2Secret,  */
    Adcx64Wrap( r9, rax);                                Store64_buffer(dst_ptr,  r9, 16, Secret, dst_b, 2);
    Adcx64Wrap(r10, rcx);                                Store64_buffer(dst_ptr, r10, 24, Secret, dst_b, 3);
    Load64_buffer(rdx, inA_ptr, 16, Secret, inA_b, 2);   Mulx64(rcx, rax, rdx);  /* A[2]^2Secret,  */
    Adcx64Wrap(r11, rax);                                Store64_buffer(dst_ptr, r11, 32, Secret, dst_b, 4);
    Adcx64Wrap(r12, rcx);                                Store64_buffer(dst_ptr, r12, 40, Secret, dst_b, 5);
    Load64_buffer(rdx, inA_ptr, 24, Secret, inA_b, 3);   Mulx64(rcx, rax, rdx);  /* A[3]^2Secret,  */
    Adcx64Wrap(r13, rax);                                Store64_buffer(dst_ptr, r13, 48, Secret, dst_b, 6);
    Adcx64Wrap(r14, rcx);                                Store64_buffer(dst_ptr, r14, 56, Secret, dst_b, 7);


}

/*
#reset-options "--z3rlimit 300"
procedure{:quick} fast_multiply_a1b(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;
        inB_ptr @= rcx;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        b0 := buffer64_read(inB_b, 0, mem);
        b1 := buffer64_read(inB_b, 1, mem);
        b2 := buffer64_read(inB_b, 2, mem);
        b3 := buffer64_read(inB_b, 3, mem);

        a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;
    reads
        dst_ptr; inA_ptr; inB_ptr; memTaint;

    modifies
        rax; rdx; r8; r9; r10; r11; r12; r13; r14;
        mem; efl;

    requires
        adx_enabled && bmi2_enabled;
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);
        validSrcAddrs64(mem, inB_ptr, inB_b, 4, memTaint, Secret);
        
        rax < pow2_64 - 1;

        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let a0b := d0 + pow2_64 * d1 + pow2_128 * r12 + pow2_192 * r14 + pow2_256 * rax; 
        a0b == a0 * b;

    ensures
        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        pow2_two(a0, a1) * b == pow2_six(d0, d1, d2, r12, r14, rax);

        validSrcAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        modifies_buffer(dst_b, old(mem), mem);
{
    xor_lemmas();

    ghost var a0b_0 := buffer64_read(dst_b, 0, mem);
    ghost var a0b_1 := buffer64_read(dst_b, 1, mem);
    ghost var a0b_2 := r12;
    ghost var a0b_3 := r14;
    ghost var a0b_4 := rax;
    ghost var a0b := pow2_five(a0b_0, a0b_1, a0b_2, a0b_3, a0b_4);
//
//    "movq  8(A), %%rdx; " /* A[1] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[1]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 8(dst),  %%r8 ;"    "movq  %%r8,  8(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[1]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 16(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[1]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"                              "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[1]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"                              "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"

    Load64_buffer(rdx, inA_ptr,  8, Secret, inA_b, 1);     /* A[1] */

    lemma_load_mem64(inB_b, 0, mem);    
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0, Secret));  /* A[1]*B[0] */ lemma_prod_bounds(r9, r8, a1, b0); 
    lemma_load_mem64(dst_b, 1, mem);    
    Xor64(r10, r10);  ghost var a1b_0 := r8;      
    Adcx64Wrap(r8, Mem(dst_ptr,  8, dst_b, 1, Secret));   
    Store64_buffer(dst_ptr, r8,  8, Secret, dst_b, 1);  // REVIEW: Why not combine the Adcx with the Store?

    lemma_load_mem64(inB_b, 1, mem);    
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1, Secret));  /* A[1]*B[1] */ lemma_prod_bounds(r11, r10, a1, b1);  lemma_overflow(r11, r10, r9, bool_bit(overflow(efl)));
    Adox64Wrap(r10,  r9);  ghost var a1b_1 := r10;      // At this point, overflow = 0, r9 < 2^64 - 1, and (r10 is <= 1 (so no new overflow), or r11 < 2^64-2)
    Adcx64Wrap(r10, r12);                         
    Store64_buffer(dst_ptr, r10, 16, Secret, dst_b, 2); 

    lemma_load_mem64(inB_b, 2, mem);    
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2, Secret));  /* A[1]*B[2] */ lemma_prod_bounds(r13, r12, a1, b2);  lemma_overflow(r13, r12, r11, bool_bit(overflow(efl)));
    Adox64Wrap(r12, r11);  ghost var a1b_2 := r12;      // At this point, either r13 < 2^64-2 or (r12 <= 1, and (overflow = 0 or r11 < 2^64 - 2)).  RHS of the first or means no overflow
    Adcx64Wrap(r12, r14); 
    Mov64( r8, 0); 

    lemma_load_mem64(inB_b, 3, mem);    
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3, Secret));  /* A[1]*B[3] */ lemma_prod_bounds(rdx, r14, a1, b3);  lemma_overflow(rdx, r14, r13, bool_bit(overflow(efl)));
    ghost var old_carry    := bool_bit(cf(efl));
    ghost var old_overflow := bool_bit(overflow(efl));
    Adox64Wrap(r14, r13);  ghost var a1b_3 := r14;      // If rdx = 2^64 - 1, then we know r14 <= 1.  If r13 < 2^64-2, then no new overflow.  Else there wasn't any previous overflow, so r13 can absorb the 1 from r14 without overflowing.
    Adcx64Wrap(r14, rax);                         
    Mov64(rax, 0);
    /*******************************************/  Adox64Wrap(rax, rdx);  ghost var a1b_4 := rax;  ghost var overflow_bit := bool_bit(overflow(efl));  Adcx64Wrap(rax, r8); 

    assert overflow_bit == 0;

    ghost var carry_bit := bool_bit(cf(efl));
    assert carry_bit == 0;

    ghost var d0 := buffer64_read(dst_b, 0, mem);
    ghost var d1 := buffer64_read(dst_b, 1, mem);
    ghost var d2 := buffer64_read(dst_b, 2, mem);

    ghost var a1b := pow2_five(a1b_0, a1b_1, a1b_2, a1b_3, a1b_4);
    ghost var a0a1b := pow2_seven(d0, d1, d2, r12, r14, rax, carry_bit);

    assert_by_tactic(a1 * b == pow2_four(a1*b0, a1*b1, a1*b2, a1*b3), int_canon);   // PASSES
    assert a1b == a1 * b;  // PASSES

    lemma_sum_a1b(
              a0, a1,
              a0b, a0b_0, a0b_1, a0b_2, a0b_3, a0b_4,
              a1b, a1b_0, a1b_1, a1b_2, a1b_3, a1b_4,
              b, b0, b1, b2, b3,
              d1, d2, r12, r14, rax,
              carry_bit); 
    assert pow2_two(a0, a1) * b == a0a1b;   // Conclusion from the lemma
}

#reset-options "--z3rlimit 300"
procedure{:quick} fast_multiply_a2b(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;
        inB_ptr @= rcx;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        b0 := buffer64_read(inB_b, 0, mem);
        b1 := buffer64_read(inB_b, 1, mem);
        b2 := buffer64_read(inB_b, 2, mem);
        b3 := buffer64_read(inB_b, 3, mem);

        a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;
    reads
        dst_ptr; inA_ptr; inB_ptr; memTaint;

    modifies
        rax; rdx; r8; r9; r10; r11; r12; r13; r14;
        mem; efl;

    requires
        adx_enabled && bmi2_enabled;
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);
        validSrcAddrs64(mem, inB_ptr, inB_b, 4, memTaint, Secret);

        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        mul_nats(pow2_two(a0, a1), b) == pow2_six(d0, d1, d2, r12, r14, rax);
    ensures
        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        let d3 := buffer64_read(dst_b, 3, mem);
        pow2_three(a0, a1, a2) * b == pow2_seven(d0, d1, d2, d3, r12, r14, rax);

        validSrcAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        modifies_buffer(dst_b, old(mem), mem);
{
    xor_lemmas();

    ghost var a0a1b_0 := buffer64_read(dst_b, 0, mem);
    ghost var a0a1b_1 := buffer64_read(dst_b, 1, mem);
    ghost var a0a1b_2 := buffer64_read(dst_b, 2, mem);
    ghost var a0a1b_3 := r12;
    ghost var a0a1b_4 := r14;
    ghost var a0a1b_5 := rax;
    ghost var a0a1b := pow2_six(a0a1b_0, a0a1b_1, a0a1b_2, a0a1b_3, a0a1b_4, a0a1b_5);

//
//    "movq 16(A), %%rdx; " /* A[2] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[2]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 16(dst), %%r8 ;"    "movq  %%r8, 16(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[2]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 24(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[2]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"                              "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[2]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"                              "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"

    Load64_buffer(rdx, inA_ptr,  16, Secret, inA_b, 2);     /* A[2] */

    lemma_load_mem64(inB_b, 0, mem);    
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0, Secret));  /* A[2]*B[0] */ lemma_prod_bounds(r9, r8, a2, b0); 
    lemma_load_mem64(dst_b, 2, mem);    
    Xor64(r10, r10);  ghost var a2b_0 := r8;      
    Adcx64Wrap(r8, Mem(dst_ptr,  16, dst_b, 2, Secret));   
    Store64_buffer(dst_ptr, r8,  16, Secret, dst_b, 2);  // REVIEW: Why not combine the Adcx with the Store?

    lemma_load_mem64(inB_b, 1, mem);    
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1, Secret));  /* A[2]*B[1] */ lemma_prod_bounds(r11, r10, a2, b1);  lemma_overflow(r11, r10, r9, bool_bit(overflow(efl)));
    Adox64Wrap(r10,  r9);  ghost var a2b_1 := r10;  
    Adcx64Wrap(r10, r12);                         
    Store64_buffer(dst_ptr, r10, 24, Secret, dst_b, 3); 

    lemma_load_mem64(inB_b, 2, mem);    
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2, Secret));  /* A[2]*B[2] */ lemma_prod_bounds(r13, r12, a2, b2);  lemma_overflow(r13, r12, r11, bool_bit(overflow(efl)));
    Adox64Wrap(r12, r11);  ghost var a2b_2 := r12; 
    Adcx64Wrap(r12, r14); 
    Mov64( r8, 0); 

    lemma_load_mem64(inB_b, 3, mem);    
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3, Secret));  /* A[2]*B[3] */ lemma_prod_bounds(rdx, r14, a2, b3);  lemma_overflow(rdx, r14, r13, bool_bit(overflow(efl))); 
    ghost var old_carry    := bool_bit(cf(efl));
    ghost var old_overflow := bool_bit(overflow(efl));
    Adox64Wrap(r14, r13);  ghost var a2b_3 := r14; 
    Adcx64Wrap(r14, rax);                         
    Mov64(rax, 0);
    /*******************************************/  Adox64Wrap(rax, rdx);  ghost var a2b_4 := rax;    Adcx64Wrap(rax, r8); 

    ghost var carry_bit    := bool_bit(cf(efl)); 
    ghost var overflow_bit := bool_bit(overflow(efl));

    assert overflow_bit == 0;
    assert carry_bit == 0;

    ghost var d0 := buffer64_read(dst_b, 0, mem);
    ghost var d1 := buffer64_read(dst_b, 1, mem);
    ghost var d2 := buffer64_read(dst_b, 2, mem);
    ghost var d3 := buffer64_read(dst_b, 3, mem);

    ghost var a2b := pow2_five(a2b_0, a2b_1, a2b_2, a2b_3, a2b_4);
    ghost var a0a1a2b := pow2_seven(d0, d1, d2, d3, r12, r14, rax);

    assert_by_tactic(a2 * b == pow2_four(a2*b0, a2*b1, a2*b2, a2*b3), int_canon);   // PASSES
    assert a2b == a2 * b;  // PASSES

    lemma_sum_a2b(a0, a1, a2,
              a0a1b, a0a1b_0, a0a1b_1, a0a1b_2, a0a1b_3, a0a1b_4, a0a1b_5,
              a2b, a2b_0, a2b_1, a2b_2, a2b_3, a2b_4,
              b, b0, b1, b2, b3,
              d2, d3, r12, r14, rax); 
    assert pow2_three(a0, a1, a2) * b == a0a1a2b;   // Conclusion from the lemma.  // PASSES
    assert d0 == a0a1b_0;       // PASSES
    assert d1 == a0a1b_1;       // PASSES
    assert pow2_three(a0, a1, a2) * b == pow2_seven(d0, d1, d2, d3, r12, r14, rax);
}



#reset-options "--z3rlimit 400"
procedure{:quick} fast_multiply_a3b(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;
        inB_ptr @= rcx;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        b0 := buffer64_read(inB_b, 0, mem);
        b1 := buffer64_read(inB_b, 1, mem);
        b2 := buffer64_read(inB_b, 2, mem);
        b3 := buffer64_read(inB_b, 3, mem);

        a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;
    reads
        dst_ptr; inA_ptr; inB_ptr; memTaint;

    modifies
        rax; rdx; r8; r9; r10; r11; r12; r13; r14;
        mem; efl;

    requires
        adx_enabled && bmi2_enabled;
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);
        validSrcAddrs64(mem, inB_ptr, inB_b, 4, memTaint, Secret);

        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        let d3 := buffer64_read(dst_b, 3, mem);
        pow2_three(a0, a1, a2) * b == pow2_seven(d0, d1, d2, d3, r12, r14, rax);
    ensures
        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        let d3 := buffer64_read(dst_b, 3, mem);
        let d4 := buffer64_read(dst_b, 4, mem);
        let d5 := buffer64_read(dst_b, 5, mem);
        let d6 := buffer64_read(dst_b, 6, mem);
        let d7 := buffer64_read(dst_b, 7, mem);
        pow2_four(a0, a1, a2, a3) * b == pow2_eight(d0, d1, d2, d3, d4, d5, d6, d7);

        validSrcAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        modifies_buffer(dst_b, old(mem), mem);
{
    xor_lemmas();

    ghost var a0a1a2b_0 := buffer64_read(dst_b, 0, mem);
    ghost var a0a1a2b_1 := buffer64_read(dst_b, 1, mem);
    ghost var a0a1a2b_2 := buffer64_read(dst_b, 2, mem);
    ghost var a0a1a2b_3 := buffer64_read(dst_b, 3, mem);
    ghost var a0a1a2b_4 := r12;
    ghost var a0a1a2b_5 := r14;
    ghost var a0a1a2b_6 := rax;
    ghost var a0a1a2b := pow2_seven(a0a1a2b_0, a0a1a2b_1, a0a1a2b_2, a0a1a2b_3, a0a1a2b_4, a0a1a2b_5, a0a1a2b_6);

//
//    "movq 24(A), %%rdx; " /* A[3] */
//    "mulx   (B),  %%r8,  %%r9; " /* A[3]*B[0] */    "xorl %%r10d, %%r10d ;"  "adcx 24(dst), %%r8 ;"   "movq  %%r8, 24(dst) ;"
//    "mulx  8(B), %%r10, %%r11; " /* A[3]*B[1] */    "adox  %%r9, %%r10 ;"    "adcx %%r12, %%r10 ;"    "movq %%r10, 32(dst) ;"
//    "mulx 16(B), %%r12, %%r13; " /* A[3]*B[2] */    "adox %%r11, %%r12 ;"    "adcx %%r14, %%r12 ;"    "movq %%r12, 40(dst) ;"    "movq $0, %%r8  ;"
//    "mulx 24(B), %%r14, %%rdx; " /* A[3]*B[3] */    "adox %%r13, %%r14 ;"    "adcx %%rax, %%r14 ;"    "movq %%r14, 48(dst) ;"    "movq $0, %%rax ;"
//    /*******************************************/   "adox %%rdx, %%rax ;"    "adcx  %%r8, %%rax ;"    "movq %%rax, 56(dst) ;"

    Load64_buffer(rdx, inA_ptr,  24, Secret, inA_b, 3);     /* A[3] */

    lemma_load_mem64(inB_b, 0, mem);    
    Mulx64( r9,  r8, Mem(inB_ptr,  0, inB_b, 0, Secret));  /* A[3]*B[0] */ lemma_prod_bounds(r9, r8, a3, b0); 
    lemma_load_mem64(dst_b, 3, mem);    
    Xor64(r10, r10);  ghost var a3b_0 := r8;      
    Adcx64Wrap(r8, Mem(dst_ptr,  24, dst_b, 3, Secret));   
    Store64_buffer(dst_ptr, r8,  24, Secret, dst_b, 3);  // REVIEW: Why not combine the Adcx with the Store?

    lemma_load_mem64(inB_b, 1, mem);    
    Mulx64(r11, r10, Mem(inB_ptr,  8, inB_b, 1, Secret));  /* A[3]*B[1] */ lemma_prod_bounds(r11, r10, a3, b1);  lemma_overflow(r11, r10, r9, bool_bit(overflow(efl)));
    Adox64Wrap(r10,  r9);  ghost var a3b_1 := r10;  
    Adcx64Wrap(r10, r12);                         
    Store64_buffer(dst_ptr, r10, 32, Secret, dst_b, 4); 

    lemma_load_mem64(inB_b, 2, mem);    
    Mulx64(r13, r12, Mem(inB_ptr, 16, inB_b, 2, Secret));  /* A[3]*B[2] */ lemma_prod_bounds(r13, r12, a3, b2);  lemma_overflow(r13, r12, r11, bool_bit(overflow(efl)));
    Adox64Wrap(r12, r11);  ghost var a3b_2 := r12; 
    Adcx64Wrap(r12, r14); 
    Store64_buffer(dst_ptr, r12, 40, Secret, dst_b, 5); 
    Mov64( r8, 0); 

    lemma_load_mem64(inB_b, 3, mem);    
    Mulx64(rdx, r14, Mem(inB_ptr, 24, inB_b, 3, Secret));  /* A[3]*B[3] */ lemma_prod_bounds(rdx, r14, a3, b3);  lemma_overflow(rdx, r14, r13, bool_bit(overflow(efl))); 
    ghost var old_carry    := bool_bit(cf(efl));
    ghost var old_overflow := bool_bit(overflow(efl));
    Adox64Wrap(r14, r13);  ghost var a3b_3 := r14; 
    Adcx64Wrap(r14, rax);                         
    Store64_buffer(dst_ptr, r14, 48, Secret, dst_b, 6); 
    Mov64(rax, 0);
    /*******************************************/  Adox64Wrap(rax, rdx);  ghost var a3b_4 := rax;    Adcx64Wrap(rax, r8); 
    Store64_buffer(dst_ptr, rax, 56, Secret, dst_b, 7); 

    ghost var carry_bit    := bool_bit(cf(efl)); 
    ghost var overflow_bit := bool_bit(overflow(efl));

    assert overflow_bit == 0;
    assert carry_bit == 0;

    ghost var d0 := buffer64_read(dst_b, 0, mem);
    ghost var d1 := buffer64_read(dst_b, 1, mem);
    ghost var d2 := buffer64_read(dst_b, 2, mem);
    ghost var d3 := buffer64_read(dst_b, 3, mem);
    ghost var d4 := buffer64_read(dst_b, 4, mem);
    ghost var d5 := buffer64_read(dst_b, 5, mem);
    ghost var d6 := buffer64_read(dst_b, 6, mem);
    ghost var d7 := buffer64_read(dst_b, 7, mem);

    ghost var a3b := pow2_five(a3b_0, a3b_1, a3b_2, a3b_3, a3b_4);
    ghost var a0a1a2a3b := pow2_eight(d0, d1, d2, d3, d4, d5, d6, d7);

    assert_by_tactic(a3 * b == pow2_four(a3*b0, a3*b1, a3*b2, a3*b3), int_canon);   // PASSES
    assert a3b == a3 * b;  // PASSES

    lemma_sum_a3b(a0, a1, a2, a3,
              a0a1a2b, a0a1a2b_0, a0a1a2b_1, a0a1a2b_2, a0a1a2b_3, a0a1a2b_4, a0a1a2b_5, a0a1a2b_6,
              a3b, a3b_0, a3b_1, a3b_2, a3b_3, a3b_4,
              b, b0, b1, b2, b3,
              d3, d4, d5, d6, d7); 
//    assert pow2_four(a0, a1, a2, a3) * b == a0a1a2a3b;   // Conclusion from the lemma.  // PASSES
}


#reset-options "--z3rlimit 20"

procedure{:quick} fast_multiply(
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64)
    lets
        dst_ptr @= rdi;
        inA_ptr @= rsi;
        inB_ptr @= rcx;

        a0 := buffer64_read(inA_b, 0, mem);
        a1 := buffer64_read(inA_b, 1, mem);
        a2 := buffer64_read(inA_b, 2, mem);
        a3 := buffer64_read(inA_b, 3, mem);

        b0 := buffer64_read(inB_b, 0, mem);
        b1 := buffer64_read(inB_b, 1, mem);
        b2 := buffer64_read(inB_b, 2, mem);
        b3 := buffer64_read(inB_b, 3, mem);

        a := pow2_four(a0, a1, a2, a3);
        b := pow2_four(b0, b1, b2, b3);
    reads
        dst_ptr; inA_ptr; inB_ptr; memTaint;

    modifies
        rax; rdx; r8; r9; r10; r11; r12; r13; r14;
        mem; efl;

    requires
        adx_enabled && bmi2_enabled;
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        validDstAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_ptr, inA_b, 4, memTaint, Secret);
        validSrcAddrs64(mem, inB_ptr, inB_b, 4, memTaint, Secret);

    ensures
        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        let d3 := buffer64_read(dst_b, 3, mem);
        let d4 := buffer64_read(dst_b, 4, mem);
        let d5 := buffer64_read(dst_b, 5, mem);
        let d6 := buffer64_read(dst_b, 6, mem);
        let d7 := buffer64_read(dst_b, 7, mem);
        let d := pow2_eight(d0, d1, d2, d3, d4, d5, d6, d7);
        d == a * b;

        validSrcAddrs64(mem, dst_ptr, dst_b, 8, memTaint, Secret);
        modifies_buffer(dst_b, old(mem), mem);
{
    fast_multiply_a0b(dst_b, inA_b, inB_b);
    fast_multiply_a1b(dst_b, inA_b, inB_b);
    fast_multiply_a2b(dst_b, inA_b, inB_b);
    fast_multiply_a3b(dst_b, inA_b, inB_b);
}

// fast_mul_stdcall(dst, inA, inB)
procedure{:quick}{:public} fast_mul_stdcall(
    inline win:bool,
    ghost dst_b:buffer64,
    ghost inA_b:buffer64,
    ghost inB_b:buffer64,
    ghost stack_b:buffer64)
    lets
        dst_ptr @= rdi; inA_ptr @= rsi; inB_ptr @= rcx;
        dst_in := (if win then rcx else rdi);
        inA_in := (if win then rdx else rsi);
        inB_in := (if win then r8 else rdx);
    reads memTaint;
    modifies
        rax; rbx; rcx; rdx; rdi; rsi; r8; r9; r10; r11; r12; r13; r14;
        rsp; efl; mem;
    requires
        adx_enabled && bmi2_enabled;
        buffers_disjoint(dst_b, inA_b);
        buffers_disjoint(dst_b, inB_b);

        buffers_disjoint(stack_b, dst_b);
        buffers_disjoint(stack_b, inA_b);
        buffers_disjoint(stack_b, inB_b);

        validDstAddrs64(mem, dst_in, dst_b, 8, memTaint, Secret);
        validSrcAddrs64(mem, inA_in, inA_b, 4, memTaint, Secret);
        validSrcAddrs64(mem, inB_in, inB_b, 4, memTaint, Secret);
        valid_stack_slots(mem, rsp, stack_b, 5, memTaint);
    ensures
        let a0 := old(buffer64_read(inA_b, 0, mem));
        let a1 := old(buffer64_read(inA_b, 1, mem));
        let a2 := old(buffer64_read(inA_b, 2, mem));
        let a3 := old(buffer64_read(inA_b, 3, mem));

        let b0 := old(buffer64_read(inB_b, 0, mem));
        let b1 := old(buffer64_read(inB_b, 1, mem));
        let b2 := old(buffer64_read(inB_b, 2, mem));
        let b3 := old(buffer64_read(inB_b, 3, mem));

        let d0 := buffer64_read(dst_b, 0, mem);
        let d1 := buffer64_read(dst_b, 1, mem);
        let d2 := buffer64_read(dst_b, 2, mem);
        let d3 := buffer64_read(dst_b, 3, mem);
        let d4 := buffer64_read(dst_b, 4, mem);
        let d5 := buffer64_read(dst_b, 5, mem);
        let d6 := buffer64_read(dst_b, 6, mem);
        let d7 := buffer64_read(dst_b, 7, mem);

        let a := a0 + pow2_64 * a1 + pow2_128 * a2 + pow2_192 * a3;
        let b := b0 + pow2_64 * b1 + pow2_128 * b2 + pow2_192 * b3;

        let d := d0 + pow2_64 * d1 + pow2_128 * d2 + pow2_192 * d3 +
                 pow2_256 * d4 + pow2_320 * d5 + pow2_384 * d6 + pow2_448 * d7;
        d == a * b;

        //////////////////////////////////////
        //   Framing
        //////////////////////////////////////

        modifies_buffer_2(dst_b, stack_b, old(mem), mem);
        validSrcAddrs64(mem, dst_in, dst_b, 8, memTaint, Secret);

        rbx == old(rbx);
        rsi == old(rsi);
        r12 == old(r12);
        r13 == old(r13);
        r14 == old(r14);

        rsp == old(rsp);
{
    // Store callee-save registers
    Push(rbx, stack_b, 4);
    Push(rsi, stack_b, 3);
    Push(r12, stack_b, 2);
    Push(r13, stack_b, 1);
    Push(r14, stack_b, 0);

    // Line up the rest of the arguments
    inline if (win) {
        Mov64(dst_ptr, rcx);
        Mov64(inA_ptr, rdx);
        Mov64(inB_ptr, r8);
    } else {
        Mov64(inB_ptr, rdx);
    }

    fast_multiply(dst_b, inA_b, inB_b);

    Pop(r14, stack_b, 0);
    Pop(r13, stack_b, 1);
    Pop(r12, stack_b, 2);
    Pop(rsi, stack_b, 3);
    Pop(rbx, stack_b, 4);
}

*/
